{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assign_time_bin(df, aggregation_period):\n",
    "    start_date = df['occ_date'].min().floor('D')  # Dataset's start date\n",
    "    end_date = df['occ_date'].max().ceil('D') + timedelta(aggregation_period) # Dataset's end date\n",
    "    print(end_date)\n",
    "    time_bins = pd.date_range(start=start_date, end=end_date, freq=f'{aggregation_period}D')\n",
    "\n",
    "    # Bin the timestamps\n",
    "    df['time_bin'] = pd.cut(\n",
    "        df['occ_date'],\n",
    "        bins=time_bins,\n",
    "        labels=time_bins[:-1],  # Label bins by their start date\n",
    "        right=False\n",
    "    )\n",
    "    df['time_bin'] = df['time_bin'].astype('datetime64[ns]')\n",
    "\n",
    "    print(df['time_bin'].dtype)\n",
    "    return df\n",
    "\n",
    "def prepare_data(crime_df, grid_df, aggregation_period):\n",
    "    relevant_columns = ['occ_date', 'x_coordinate', 'y_coordinate']\n",
    "    crime_df = crime_df[relevant_columns]\n",
    "\n",
    "    crime_df = gpd.GeoDataFrame(crime_df, geometry=gpd.points_from_xy(crime_df.x_coordinate, crime_df.y_coordinate))\n",
    "    crime_df.set_crs('EPSG:2913', inplace=True)\n",
    "\n",
    "    grid_crime_df = gpd.sjoin(crime_df, grid_df, how='left', predicate='within')\n",
    "    grid_crime_df.dropna(inplace=True) # drop those crimes that don't fall within any grids inside the city boundry\n",
    "\n",
    "    grid_crime_df.drop('index_right', axis=1, inplace=True)\n",
    "\n",
    "    grid_crime_df['occ_date'] = pd.to_datetime(grid_crime_df['occ_date'])  # Ensure time is datetime\n",
    "    grid_crime_df['hotspot'] = grid_crime_df['hotspot'].astype('int64')  \n",
    "    grid_crime_df['unique_id'] = grid_crime_df['unique_id'].astype('int64') \n",
    "\n",
    "    # Aggregate crime counts over 14 days period\n",
    "    # grid_crime_df['time_bin'] = grid_crime_df['occ_date'].dt.floor(f'{aggregation_period}D') # doesn't allow for custom bins\n",
    "    grid_crime_df = assign_time_bin(grid_crime_df, aggregation_period)\n",
    "    grid_crime_df['day_of_week'] = grid_crime_df['occ_date'].dt.dayofweek\n",
    "\n",
    "    grid_crime_df.drop(columns=['x_index','y_index'],axis=1, inplace =True)\n",
    "\n",
    "    crime_counts_df = grid_crime_df.groupby(['unique_id', 'time_bin']).size().reset_index(name='crime_count')\n",
    "\n",
    "    return crime_counts_df\n",
    "\n",
    "def fill_in_hotspots(crime_counts_df,  hotspot_cells, threshold):\n",
    "    \n",
    "    # hotspot_cells = crime_counts_df.groupby(['unique_id']).agg({'crime_count': lambda x: any(x >= 5)})\n",
    "\n",
    "    # hotspot_cells = hotspot_cells[hotspot_cells['crime_count'] == True].index\n",
    "\n",
    "    potential_hotspots_crime_counts_df = crime_counts_df[crime_counts_df['unique_id'].isin(hotspot_cells)]\n",
    "    potential_hotspots_crime_counts_df.loc[:,'hotspot'] = 0\n",
    "    potential_hotspots_crime_counts_df.loc[ potential_hotspots_crime_counts_df['crime_count'] >= threshold , 'hotspot'] = 1\n",
    "\n",
    "    return potential_hotspots_crime_counts_df\n",
    "\n",
    "def create_sequences(df, seq_length):\n",
    "    sequences = []\n",
    "    for cell_id in df['unique_id'].unique():\n",
    "        cell_data = df[df['unique_id'] == cell_id].sort_values('time_bin')\n",
    "        for i in range(len(cell_data) - seq_length ):\n",
    "            sequence = cell_data.iloc[i: i + seq_length + 1]\n",
    "            sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-14 00:00:00\n",
      "datetime64[ns]\n",
      "2017-06-14 00:00:00\n",
      "datetime64[ns]\n",
      "5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7051/3142646419.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  potential_hotspots_crime_counts_df.loc[:,'hotspot'] = 0\n",
      "/tmp/ipykernel_7051/3142646419.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  potential_hotspots_crime_counts_df.loc[:,'hotspot'] = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_dir = os.getcwd()\n",
    "train_base_dir = os.path.join(current_dir, \"Data\", \"train\")\n",
    "test_base_dir = os.path.join(current_dir, \"Data\", \"test\")\n",
    "cell_size = 600\n",
    "aggregation_period = 14 # In days\n",
    "\n",
    "train_crime_df = pd.read_csv(os.path.join(train_base_dir,'combined_train_data.csv'))\n",
    "test_crime_df = pd.read_csv(os.path.join(test_base_dir,'test_data.csv'))\n",
    "\n",
    "grid_df = gpd.read_file(os.path.join(current_dir, 'Data', 'grids', str(cell_size),  'crime-forecast-grid.shp'))\n",
    "\n",
    "train_crime_counts_df = prepare_data(train_crime_df, grid_df, aggregation_period)\n",
    "test_crime_counts_df = prepare_data(test_crime_df, grid_df, aggregation_period)\n",
    "\n",
    "threshold = train_crime_counts_df.crime_count.quantile(0.98)\n",
    "print(threshold)\n",
    "hotspot_cells = train_crime_counts_df.groupby(['unique_id']).agg({'crime_count': lambda x: any(x >= threshold)})\n",
    "\n",
    "hotspot_cells = hotspot_cells[hotspot_cells['crime_count'] == True].index\n",
    "\n",
    "\n",
    "train_hotspots_crime_counts_df = fill_in_hotspots(train_crime_counts_df, hotspot_cells, threshold)\n",
    "test_hotspots_crime_counts_df = fill_in_hotspots(test_crime_counts_df, hotspot_cells, threshold)\n",
    "\n",
    "\n",
    "sequence_length = 26 # looking over whole year data to capture seasonal trend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>time_bin</th>\n",
       "      <th>crime_count</th>\n",
       "      <th>hotspot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1290</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1290</td>\n",
       "      <td>2017-03-15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1290</td>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1290</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1290</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>11781</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6369</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6371</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6372</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1428 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id   time_bin  crime_count  hotspot\n",
       "40         1290 2017-03-01            3        0\n",
       "41         1290 2017-03-15            2        0\n",
       "42         1290 2017-03-29            2        0\n",
       "43         1290 2017-04-12            1        0\n",
       "44         1290 2017-04-26            4        0\n",
       "...         ...        ...          ...      ...\n",
       "6353      11781 2017-05-24            1        0\n",
       "6369      11822 2017-03-29            1        0\n",
       "6370      11822 2017-04-12            2        0\n",
       "6371      11822 2017-04-26            3        0\n",
       "6372      11822 2017-05-24            1        0\n",
       "\n",
       "[1428 rows x 4 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hotspots_crime_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>time_bin</th>\n",
       "      <th>crime_count</th>\n",
       "      <th>hotspot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>11781</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6369</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6371</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6372</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6974 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id   time_bin  crime_count  hotspot\n",
       "839        1290 2016-03-10            1        0\n",
       "840        1290 2016-03-24            2        0\n",
       "841        1290 2016-04-07            1        0\n",
       "842        1290 2016-04-21            2        0\n",
       "843        1290 2016-05-05            2        0\n",
       "...         ...        ...          ...      ...\n",
       "6353      11781 2017-05-24            1        0\n",
       "6369      11822 2017-03-29            1        0\n",
       "6370      11822 2017-04-12            2        0\n",
       "6371      11822 2017-04-26            3        0\n",
       "6372      11822 2017-05-24            1        0\n",
       "\n",
       "[6974 rows x 4 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "last_time_bin = train_hotspots_crime_counts_df.time_bin.max()\n",
    "start_time_bin_test_data_dependends_upon = last_time_bin - timedelta(aggregation_period*(sequence_length-1))\n",
    "historical_data_for_test_df = train_hotspots_crime_counts_df[train_hotspots_crime_counts_df.time_bin >= start_time_bin_test_data_dependends_upon ]\n",
    "test_hotspots_crime_counts_df = pd.concat([historical_data_for_test_df, test_hotspots_crime_counts_df])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_bins = pd.date_range(train_crime_counts_df.time_bin.min(), train_crime_counts_df.time_bin.max(), freq='14d')\n",
    "test_time_bins_history = pd.date_range(start_time_bin_test_data_dependends_upon, train_crime_counts_df.time_bin.max(), freq='14d')\n",
    "test_time_bins_current = pd.date_range(test_crime_counts_df.time_bin.min(), test_crime_counts_df.time_bin.max(), freq='14d')\n",
    "test_time_bins = test_time_bins_history.append(test_time_bins_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>time_bin</th>\n",
       "      <th>crime_count</th>\n",
       "      <th>hotspot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>11781</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6369</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6371</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6372</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6974 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id   time_bin  crime_count  hotspot\n",
       "839        1290 2016-03-10            1        0\n",
       "840        1290 2016-03-24            2        0\n",
       "841        1290 2016-04-07            1        0\n",
       "842        1290 2016-04-21            2        0\n",
       "843        1290 2016-05-05            2        0\n",
       "...         ...        ...          ...      ...\n",
       "6353      11781 2017-05-24            1        0\n",
       "6369      11822 2017-03-29            1        0\n",
       "6370      11822 2017-04-12            2        0\n",
       "6371      11822 2017-04-26            3        0\n",
       "6372      11822 2017-05-24            1        0\n",
       "\n",
       "[6974 rows x 4 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hotspots_crime_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 1290,  1292,  1370,  1371,  1448,  1522,  1637,  1752,  1753,  2096,\n",
       "       ...\n",
       "       11515, 11516, 11517, 11586, 11587, 11686, 11693, 11735, 11781, 11822],\n",
       "      dtype='int64', name='unique_id', length=351)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# test_time_bins = np.concatenate([test_time_bin_history, test_time_bins])\n",
    "\n",
    "# Create every possible hotspot_cell-time_bin combination\n",
    "grid_time_bin_train_df = pd.DataFrame([(grid, time_bin) for grid in hotspot_cells for time_bin in train_time_bins],columns=['unique_id', 'time_bin'])\n",
    "grid_time_bin_test_df = pd.DataFrame([(grid, time_bin) for grid in hotspot_cells for time_bin in test_time_bins.sort_values()],columns=['unique_id', 'time_bin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>time_bin</th>\n",
       "      <th>crime_count</th>\n",
       "      <th>hotspot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11578</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11579</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11580</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11581</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11582</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11583 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_id   time_bin  crime_count  hotspot\n",
       "0           1290 2016-03-10          1.0      0.0\n",
       "1           1290 2016-03-24          2.0      0.0\n",
       "2           1290 2016-04-07          1.0      0.0\n",
       "3           1290 2016-04-21          2.0      0.0\n",
       "4           1290 2016-05-05          2.0      0.0\n",
       "...          ...        ...          ...      ...\n",
       "11578      11822 2017-03-29          1.0      0.0\n",
       "11579      11822 2017-04-12          2.0      0.0\n",
       "11580      11822 2017-04-26          3.0      0.0\n",
       "11581      11822 2017-05-10          0.0      0.0\n",
       "11582      11822 2017-05-24          1.0      0.0\n",
       "\n",
       "[11583 rows x 4 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hotspots_crime_counts_df = grid_time_bin_train_df.merge(train_hotspots_crime_counts_df, on=['unique_id', 'time_bin'], how='left').fillna(0)\n",
    "test_hotspots_crime_counts_df = grid_time_bin_test_df.merge(test_hotspots_crime_counts_df, on=['unique_id', 'time_bin'], how='left').fillna(0)\n",
    "test_hotspots_crime_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hotspots_crime_counts_df['hotspot'] = train_hotspots_crime_counts_df['hotspot'].astype(int)\n",
    "test_hotspots_crime_counts_df['hotspot'] = test_hotspots_crime_counts_df['hotspot'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>time_bin</th>\n",
       "      <th>crime_count</th>\n",
       "      <th>hotspot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1290</td>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11578</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11579</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11580</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11581</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11582</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11583 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_id   time_bin  crime_count  hotspot\n",
       "0           1290 2016-03-10          1.0        0\n",
       "1           1290 2016-03-24          2.0        0\n",
       "2           1290 2016-04-07          1.0        0\n",
       "3           1290 2016-04-21          2.0        0\n",
       "4           1290 2016-05-05          2.0        0\n",
       "...          ...        ...          ...      ...\n",
       "11578      11822 2017-03-29          1.0        0\n",
       "11579      11822 2017-04-12          2.0        0\n",
       "11580      11822 2017-04-26          3.0        0\n",
       "11581      11822 2017-05-10          0.0        0\n",
       "11582      11822 2017-05-24          1.0        0\n",
       "\n",
       "[11583 rows x 4 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_hotspots_crime_counts_df = train_hotspots_crime_counts_df.sort_values(['unique_id', 'time_bin'])\n",
    "test_hotspots_crime_counts_df = test_hotspots_crime_counts_df.sort_values(['unique_id', 'time_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences = create_sequences(train_hotspots_crime_counts_df, seq_length=sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>time_bin</th>\n",
       "      <th>crime_count</th>\n",
       "      <th>hotspot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45954</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-02-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45955</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45956</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45957</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45958</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45959</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45960</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-05-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45961</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45962</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45963</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45964</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-07-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45965</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-07-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45966</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-08-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45967</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45968</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45969</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45970</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45971</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-10-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45972</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-11-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45973</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45974</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45975</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45976</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45977</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45978</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45979</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45980</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-02-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_id   time_bin  crime_count  hotspot\n",
       "45954      11822 2016-02-25          0.0        0\n",
       "45955      11822 2016-03-10          0.0        0\n",
       "45956      11822 2016-03-24          0.0        0\n",
       "45957      11822 2016-04-07          0.0        0\n",
       "45958      11822 2016-04-21          0.0        0\n",
       "45959      11822 2016-05-05          3.0        0\n",
       "45960      11822 2016-05-19          0.0        0\n",
       "45961      11822 2016-06-02          1.0        0\n",
       "45962      11822 2016-06-16          0.0        0\n",
       "45963      11822 2016-06-30          0.0        0\n",
       "45964      11822 2016-07-14          0.0        0\n",
       "45965      11822 2016-07-28          0.0        0\n",
       "45966      11822 2016-08-11          0.0        0\n",
       "45967      11822 2016-08-25          0.0        0\n",
       "45968      11822 2016-09-08          0.0        0\n",
       "45969      11822 2016-09-22          1.0        0\n",
       "45970      11822 2016-10-06          5.0        1\n",
       "45971      11822 2016-10-20          0.0        0\n",
       "45972      11822 2016-11-03          3.0        0\n",
       "45973      11822 2016-11-17          2.0        0\n",
       "45974      11822 2016-12-01          2.0        0\n",
       "45975      11822 2016-12-15          2.0        0\n",
       "45976      11822 2016-12-29          3.0        0\n",
       "45977      11822 2017-01-12          2.0        0\n",
       "45978      11822 2017-01-26          2.0        0\n",
       "45979      11822 2017-02-09          0.0        0\n",
       "45980      11822 2017-02-23          0.0        0"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sequences[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_sequences = create_sequences(test_hotspots_crime_counts_df, seq_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>time_bin</th>\n",
       "      <th>crime_count</th>\n",
       "      <th>hotspot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11556</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11557</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11558</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11559</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-07-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11560</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-07-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-08-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11562</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11563</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11564</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11565</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11566</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-10-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11567</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-11-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11568</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11569</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11570</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11571</th>\n",
       "      <td>11822</td>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11572</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11573</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11574</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11575</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-02-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11576</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11577</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-03-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11578</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11579</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11580</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11581</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11582</th>\n",
       "      <td>11822</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_id   time_bin  crime_count  hotspot\n",
       "11556      11822 2016-06-02          1.0        0\n",
       "11557      11822 2016-06-16          0.0        0\n",
       "11558      11822 2016-06-30          0.0        0\n",
       "11559      11822 2016-07-14          0.0        0\n",
       "11560      11822 2016-07-28          0.0        0\n",
       "11561      11822 2016-08-11          0.0        0\n",
       "11562      11822 2016-08-25          0.0        0\n",
       "11563      11822 2016-09-08          0.0        0\n",
       "11564      11822 2016-09-22          1.0        0\n",
       "11565      11822 2016-10-06          5.0        1\n",
       "11566      11822 2016-10-20          0.0        0\n",
       "11567      11822 2016-11-03          3.0        0\n",
       "11568      11822 2016-11-17          2.0        0\n",
       "11569      11822 2016-12-01          2.0        0\n",
       "11570      11822 2016-12-15          2.0        0\n",
       "11571      11822 2016-12-29          3.0        0\n",
       "11572      11822 2017-01-12          2.0        0\n",
       "11573      11822 2017-01-26          2.0        0\n",
       "11574      11822 2017-02-09          0.0        0\n",
       "11575      11822 2017-02-23          0.0        0\n",
       "11576      11822 2017-03-01          0.0        0\n",
       "11577      11822 2017-03-15          0.0        0\n",
       "11578      11822 2017-03-29          1.0        0\n",
       "11579      11822 2017-04-12          2.0        0\n",
       "11580      11822 2017-04-26          3.0        0\n",
       "11581      11822 2017-05-10          0.0        0\n",
       "11582      11822 2017-05-24          1.0        0"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_sequences[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "positive_data = []\n",
    "negative_data = []\n",
    "for sequence in training_sequences:\n",
    "    if sequence['hotspot'].iloc[-1] == 1:\n",
    "        positive_data.append(sequence)\n",
    "    else:\n",
    "        negative_data.append(sequence)\n",
    "\n",
    "print(len(positive_data))\n",
    "negative_data = resample(negative_data, replace=False,  n_samples=len(positive_data), random_state=1) \n",
    "\n",
    "balanced_data = positive_data + negative_data\n",
    "\n",
    "\n",
    "\n",
    "train_data, val_data = train_test_split(balanced_data, test_size=0.1, random_state=1)\n",
    "\n",
    "test_data = testing_sequences\n",
    "# # Split the remaining set into validation and test sets\n",
    "# val_data, test_data = train_test_split(val_test_data, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>time_bin</th>\n",
       "      <th>crime_count</th>\n",
       "      <th>hotspot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29886</th>\n",
       "      <td>8806</td>\n",
       "      <td>2012-11-08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29887</th>\n",
       "      <td>8806</td>\n",
       "      <td>2012-11-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29888</th>\n",
       "      <td>8806</td>\n",
       "      <td>2012-12-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29889</th>\n",
       "      <td>8806</td>\n",
       "      <td>2012-12-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29890</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29891</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-01-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29892</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-01-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29893</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29894</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-02-28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29895</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-03-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29896</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29897</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-04-11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29898</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-04-25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29899</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-05-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29900</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-05-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29901</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29902</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-06-20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29903</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-07-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29904</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-07-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29905</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29906</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29907</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-08-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29908</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-09-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29909</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29910</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-10-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29911</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-10-24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29912</th>\n",
       "      <td>8806</td>\n",
       "      <td>2013-11-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_id   time_bin  crime_count  hotspot\n",
       "29886       8806 2012-11-08          2.0        0\n",
       "29887       8806 2012-11-22          1.0        0\n",
       "29888       8806 2012-12-06          0.0        0\n",
       "29889       8806 2012-12-20          0.0        0\n",
       "29890       8806 2013-01-03          1.0        0\n",
       "29891       8806 2013-01-17          0.0        0\n",
       "29892       8806 2013-01-31          1.0        0\n",
       "29893       8806 2013-02-14          0.0        0\n",
       "29894       8806 2013-02-28          2.0        0\n",
       "29895       8806 2013-03-14          0.0        0\n",
       "29896       8806 2013-03-28          0.0        0\n",
       "29897       8806 2013-04-11          2.0        0\n",
       "29898       8806 2013-04-25          2.0        0\n",
       "29899       8806 2013-05-09          0.0        0\n",
       "29900       8806 2013-05-23          1.0        0\n",
       "29901       8806 2013-06-06          3.0        0\n",
       "29902       8806 2013-06-20          2.0        0\n",
       "29903       8806 2013-07-04          1.0        0\n",
       "29904       8806 2013-07-18          1.0        0\n",
       "29905       8806 2013-08-01          0.0        0\n",
       "29906       8806 2013-08-15          1.0        0\n",
       "29907       8806 2013-08-29          1.0        0\n",
       "29908       8806 2013-09-12          2.0        0\n",
       "29909       8806 2013-09-26          1.0        0\n",
       "29910       8806 2013-10-10          2.0        0\n",
       "29911       8806 2013-10-24          3.0        0\n",
       "29912       8806 2013-11-07          0.0        0"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4046, 26, 1), (2457, 26, 1), (4046,), (2457,))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'train_samples', 'val_samples', and 'test_samples' are the lists of samples\n",
    "\n",
    "def prepare_trainable_data(samples):\n",
    "    X = []\n",
    "    y = []\n",
    "    for seq in samples:\n",
    "        X_seq = seq[['crime_count']].values  # Select features for X\n",
    "        X.append(X_seq[:-1])  # Exclude the last time step from X\n",
    "        y.append(seq['hotspot'].iloc[-1])  # Use the last time step's 'hotspot' value as y\n",
    "    # return X, y\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare training data\n",
    "X_train, y_train = prepare_trainable_data(train_data)\n",
    "\n",
    "# Prepare validation data\n",
    "X_val, y_val = prepare_trainable_data(val_data)\n",
    "\n",
    "# Prepare test data\n",
    "X_test, y_test = prepare_trainable_data(test_data)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=20)),\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate= 0.0001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.5671 - loss: 0.6377 - val_accuracy: 0.8000 - val_loss: 0.5323\n",
      "Epoch 2/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8137 - loss: 0.4875 - val_accuracy: 0.8089 - val_loss: 0.4542\n",
      "Epoch 3/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8160 - loss: 0.4354 - val_accuracy: 0.8111 - val_loss: 0.4404\n",
      "Epoch 4/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8204 - loss: 0.4228 - val_accuracy: 0.8111 - val_loss: 0.4371\n",
      "Epoch 5/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8136 - loss: 0.4282 - val_accuracy: 0.8111 - val_loss: 0.4338\n",
      "Epoch 6/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8153 - loss: 0.4294 - val_accuracy: 0.8111 - val_loss: 0.4314\n",
      "Epoch 7/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8140 - loss: 0.4246 - val_accuracy: 0.8089 - val_loss: 0.4308\n",
      "Epoch 8/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8151 - loss: 0.4219 - val_accuracy: 0.8133 - val_loss: 0.4289\n",
      "Epoch 9/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.8075 - loss: 0.4301 - val_accuracy: 0.8178 - val_loss: 0.4310\n",
      "Epoch 10/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8300 - loss: 0.3979 - val_accuracy: 0.8089 - val_loss: 0.4281\n",
      "Epoch 11/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.8216 - loss: 0.4110 - val_accuracy: 0.8200 - val_loss: 0.4298\n",
      "Epoch 12/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.8207 - loss: 0.4057 - val_accuracy: 0.8178 - val_loss: 0.4294\n",
      "Epoch 13/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8150 - loss: 0.4176 - val_accuracy: 0.8156 - val_loss: 0.4273\n",
      "Epoch 14/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8115 - loss: 0.4213 - val_accuracy: 0.8178 - val_loss: 0.4285\n",
      "Epoch 15/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8072 - loss: 0.4187 - val_accuracy: 0.8244 - val_loss: 0.4300\n",
      "Epoch 16/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8191 - loss: 0.4073 - val_accuracy: 0.8200 - val_loss: 0.4286\n",
      "Epoch 17/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8181 - loss: 0.4075 - val_accuracy: 0.8178 - val_loss: 0.4337\n",
      "Epoch 18/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8252 - loss: 0.4095 - val_accuracy: 0.8267 - val_loss: 0.4304\n",
      "Epoch 19/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8209 - loss: 0.4090 - val_accuracy: 0.8178 - val_loss: 0.4259\n",
      "Epoch 20/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8149 - loss: 0.4157 - val_accuracy: 0.8156 - val_loss: 0.4260\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, )\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAGwCAYAAAC99fF4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABi4UlEQVR4nO3deVhUZf8G8HsYmBn2TWRRQNxSAU2hVBTtVcOlLNPcKlLTem1Ts01fs8x8wywry1dLf6hZpmYuWW5hqWmmmYobpKQoqAPIvg8wc35/HGZwZNiGYYbB+3Ndc8WcOctzONrcPud7nkciCIIAIiIiItJjY+kGEBERETVHDElEREREBjAkERERERnAkERERERkAEMSERERkQEMSUREREQGMCQRERERGWBr6QZYK41Gg5s3b8LZ2RkSicTSzSEiIqJ6EAQBBQUF8PPzg41N7X1FDElGunnzJvz9/S3dDCIiIjJCamoq2rZtW+s6DElGcnZ2BiD+kl1cXCzcGiIiIqqP/Px8+Pv7677Ha8OQZCTtLTYXFxeGJCIiIitTn1IZFm4TERERGcCQRERERGQAQxIRERGRAQxJRERERAYwJBEREREZwJBEREREZABDEhEREZEBDElEREREBjAkERERERnAkERERERkAEMSERERkQEMSUREREQGMCQRERG1RBo1UFZs6VZYNYYkIiKilibtHPC/3sBHnYAzmyzdGqtl8ZC0YsUKBAUFQaFQICwsDIcPH651/Q0bNqBHjx5wcHCAr68vpkyZgqysLN3nq1evRmRkJNzd3eHu7o4hQ4bgzz//1NvHggULIJFI9F4+Pj5Ncn5ERERmIwjAyXXA6sFAVhJQVghs/zfww0tAeYmlW2d1LBqSNm/ejFmzZmHevHk4ffo0IiMjMXz4cKSkpBhc/8iRI3j66acxdepUXLhwAVu2bMGJEycwbdo03ToHDx7ExIkTceDAAfzxxx8ICAhAVFQUbty4obev4OBgKJVK3evcuXNNeq5ERERNSlUIbHsO+HEmoFYBnaKAAa8DkACnvxaDU2aSpVtpVSSCIAiWOnjv3r3Rq1cvrFy5Uresa9euGDVqFGJiYqqt/9FHH2HlypW4fPmybtnnn3+OJUuWIDU11eAx1Go13N3dsXz5cjz99NMAxJ6kHTt2ID4+vt5tValUUKlUuvf5+fnw9/dHXl4eXFxc6r0fIiIik0u/AHw3Sew9kkiBwfOBiJmAjQ1w5SCwdRpQdAuQOQEjlwGhj1u6xRaTn58PV1fXen1/W6wnqaysDCdPnkRUVJTe8qioKBw9etTgNhEREbh+/Tp2794NQRCQnp6O77//Hg899FCNxykuLkZ5eTk8PDz0liclJcHPzw9BQUGYMGECrly5Umt7Y2Ji4Orqqnv5+/vX80yJiKhJlOQAv30EHPwAyLpc9/ot1elvqm6vOfsBk3cB/V8RAxIAtH8AmH4EaBcp3n7bOhX4cRZQXmrJVlsFi4WkzMxMqNVqeHt76y339vZGWlqawW0iIiKwYcMGjB8/HjKZDD4+PnBzc8Pnn39e43HmzJmDNm3aYMiQIbplvXv3xvr167Fv3z6sXr0aaWlpiIiI0KttutPcuXORl5ene9XUc0VERE1MXQ4c/xL4rCfw63vAwfeBz3sBa4YBp74GVAWWbqF5lBUB258HfngRqCgBOgwGph8GAvtWX9fZB3j6B2DAGwAkwMm1QOyQuztc1oPFC7clEonee0EQqi3TSkhIwIwZM/D222/j5MmT2Lt3L5KTkzF9+nSD6y9ZsgQbN27Etm3boFAodMuHDx+OMWPGIDQ0FEOGDMGuXbsAAF999VWN7ZTL5XBxcdF7ERGRGQkCcHEvsKIvsOcNsSfJqyvQcQggsQFS/gB2vgR81BnYPh1I/g3QaCzd6qaR8TewehBw5lvx3AfNB578HnBsVfM2NlJg0Dzgqa2AQyvxCbgvBwIXtpuv3VbG1lIHbtWqFaRSabVeo4yMjGq9S1oxMTHo168fXn/9dQBA9+7d4ejoiMjISCxatAi+vr66dT/66CO8//772L9/P7p3715rWxwdHREaGoqkJBa0ERE1S2nngZ/nifU1gPgl/6//AL0mAVJbIP+m+Kh7/LfibaczG8WXWwDQ4wng3omAeztLnoHpxG8Eds0GyosBJx/g8VigXf/6b9+xssfp+6lAylFgy2Tg6u/A0P8CtvIma7Y1slhPkkwmQ1hYGOLi4vSWx8XFISIiwuA2xcXFsLHRb7JUKgUg9kBpffjhh3jvvfewd+9ehIeH19kWlUqFxMREvZBFRETNQGEGsHMG8GWkGJCkMqDfTGDGKeC+qWJAAgAXPyByNvDSCWBqHBA2GZC7ALkpwKHFwLIewLqHxYBRVmTJMzJeWbF4a23HdDEgtX9ADDsNCUhaLn7ApB+B/rPF9ydWA7EPAtnJJm2ytbPo022bN29GdHQ0vvjiC/Tt2xerVq3C6tWrceHCBQQGBmLu3Lm4ceMG1q9fDwBYt24dnn32WXz22WcYOnQolEolZs2aBRsbGxw/fhyAeItt/vz5+Pbbb9GvXz/dsZycnODk5AQAeO211zBy5EgEBAQgIyMDixYtwqFDh3Du3DkEBgbWq+0NqY4nIqIGKi8Fjv0POPyxWGwMAN0eBYa8C3gE1XMfJUDiT0D8hsoeqMqvO5kT0G0U0PNJIKAvUEOJR7OSmQR89zSQkQBAAjwwFxjwmngLrbGS4sShA0qyAbkr8OhyoNsjjd9vM9WQ72+LhiRAHExyyZIlUCqVCAkJwSeffIIBAwYAACZPnoyrV6/i4MGDuvU///xzfPHFF0hOToabmxsGDRqEDz74AG3atAEAtGvXDteuXat2nHfeeQcLFiwAAEyYMAG//fYbMjMz4eXlhT59+uC9995Dt27d6t1uhiQioiYgCMCFbUDcAiCvcsw8v57A0BjDBcn1lZsKnK28HZd929PM7kHAvU8CPSYAbs30qeWzW8Sxj8qLAMfWwJj/A9oPNO0x8q4D3z8DpIodDug9HXjwPcBWZtrjNANWFZKsFUMSEZGJXf8L2DsXuF45S4KzHzDkHSB0XNXj7I0lCEDKMSD+G+DCjqpeKkjE4HHvk0CXhwGZg2mO1xjlJcDeOeII2oD4CP+YWMDZcN1uo6nLgV8WAkc/E9/79QLGrgPc63eHxVowJJkBQxIRkYnkpgK/vAuc2yK+t3MA+s0CIl5u2rBSVgQk/iiOM3T1timx5C5A8GNiYPK/3zK347Iui4NDpp8DIAEGvgEMfFPv9pogCChTa1BSpkZx5au0XPtzBUrL1QAk8HCUwdNJBk9HGVzt7Wp8glzn4l5xKpPSXEDhCoxaCXSpeTxCY6k1Am4VqJCeX4q0/FLxv3nizxn5KqTll2Jw19aYO7yrSY/LkGQGDElEBECcaf3QEiD3GuAdAviEii8Hj7q3vdupCoEjnwB/LAcqKgc27PGEOFq0i59525JzTXwaLn6DWOyt5dkR6DAI8OkuXtfWXRv9BFhBaTnS80uRnq/CrQKVLtSUlKlRXK5G+/SfMfJaDBSaYuTbuOF/Hm/gT5t7UVKmRkllCNL+rNY07Cvc1kYCd0cxMInBSQ4PRxlaOcng4SjXhSkvzS202f8CbG/+JW7Y9yVgyAJAalfnMQRBQIGqAul54jneHoDStT/nl+JWgQp1NT+qmzdWPV33A1gNwZBkBgxJRISKMvFf3Be2Vf/Mpa34perbvSo4uQVaR5FwU9OoxTDy6yKgMF1cFthPfATdr6eF26YBrv0u1i4l7BCfIrudjS3Q6h796+oTCti7o0KtQUZlz0hVr4hKLxik55WiqExt8NBylGGe7QY8bSs+9X1c0wUvl72MDLjX2Ww7qQQKOykcZFI4yGxhbyeFvUwKQRCQXVSGrMIyFKgqGvSrsEMF5thtwlTpbgBAkqwrNvgvgI1bADydZPBwlKG0XK07r/T8ql6h4hrO8U5SGwlaO8vh7aKAt4scPi4KeLsq4OMivvw9HODvYdreRIYkM2BIIrp7lZSpcfF6Brz2PIs2tw6jHLb4QfYQ2kgy0V6dDO+Kmwa3q7BzRqlnN2i8Q2Hj1x2KtvfC1rtriyyOrVHyb8C+/4gDGQLi2EUPvgd0Hdn8AqSqALi0D8KNU1Arz0KSdg5SVa7BVW/CC+fVAUgQApGgCcQFTTvcQCsAhs/JWW4Lb1cFvJzkcJTbIgBpeEb5LtqWXgIA/OU/BWc7vQiFXA4HmRh4HGRSXfhxkNnCQSbVBSM7ad01W6oKtS4wZRWVIbtIpfs5q1CF7KIyZBaWIbtIfBVWhqoHbf7CR3ZfwFVSjBzBCbPLn8cBTd1h1kVhC28XBXxcFeJ/bwtA2kDk6SSH1Ma8150hyQwYkojuDlmFKly4mY8EZT4Sbubjws083Mq8hVV2S9HHJhElggzTy1/BIU0P3TbOKEYXSQq62VxDN8k1BNtcRSfJdcgl1f8lXy5IkWzjj6u2HXBD0REZjp2R63IPZI7ucLG3g6u9HVwUdvB1UyColSP8XO1hY+YvFZPIugz8/BZwUeyVgNwVGPg6cP9zFhnAsKxCg5xibWC4PSDoB4esojJk5KtQUq4GIMAX2ehmcxXBkmuV1/cqAmxuGTxGkY0TMhw6I9+tC8q9QmDbpgec2wbDx90ZjvLbxnJO+AH44SVAlQ/YewCjVwOdhhjcpzmVlleFqqL0f9D58Ax45J4HABzwnIhvnSbBTiarCkCVLzEUyeEgs9h41bViSDIDhiQiE1JXALf+Bry6VA0OaGYajYCU7GIkKMUglFAZjNLzVXrruaEAX8k+QA+bKyiWOGBbl4/h0mUgPB1lKCgtR35JBfJKypFfWo78knLkl1Ygv6QcxSXFcC26Cr/SJASWX0FnTTK62VyFq6TYYHtSNV64ILRDgiZQ1ztxE56Q2UrRztMBQa0c0a6VI9q3ckQ7T0cEeTnCy0led1GuOQmCWKt1/Evgz1WApkKcoT78GeCBObVPodFAFWoNsitDjxh4VHq9JtqeEu1n+aUNu/UEAK72drreEG9nua6HpK2iDAEVyfAq+htO2YmQpJ8Tpw3RlFffiVQm/jn37S7WOWUmiQM5AoB/H+DxNYBrm0b+NppIRRkQNx84/oX43r8PMHIZ0Kqz6Z4+NAOGJDNgSKL6KClT48z1XJy8loO/rmbjWnYxfFwUaOtuj7buDmjrbg9/D/G/rZ0VZu92thRBEHA9pwRX/z4NxfmN6JS+G27qLFyQdsVyz/+g3NEPLva2cFHYwcXeDi4K28r/Vvas3PaZs9y2wT0rqgo1ktIL9cJQorJAd3vhTkGtHNHNzwXhHiqMTXwZTnlJ4r/4o7cDfvca9TsoV2tQWFKOwoyrUCvPQJJ2HvLM83DOTYRjieHbdTmCk15oShACcVnwQ0XlDFOOMimCvMTQ1L4yRAVVvtwcmviWnrocuHURSDsr3kpLOyf+XJpXtU7HB4GoRUDrLgZ3UVqurgyXFcgvLRfD5m1B8/bPbl+eU1yG3GIDgaQONhKIxcqOMr0nwDyd9IuZtTUz9rIGDNxYUQZkXgSUt/8+zgGqPMPr95spzr9Wj8Joi7u95wsAZM6Aj/ahBdMVuDcVhiQzYEgiQzIKSnHyag7+uia+LtzIQ0U9nz6xk0rg52YvBig3B/h7VAWptu4OaO0st8rbLGUVGiRlFOjCSPL1m2ifvhcjNQfR0+afautnC06YXf4CDmrurdf+JRLASV49UGlvU2kDlVojIDFNvGX2T0ahwesis7VBFx9ndPN1QTc/FwT7ueAeHxc4yW2BnKvA+kfF/zr7AtE7avyyb7SSHHGuMm3QUJ4Vv3A11UNcGexwxSYAZ8r9caGyFuZvIQBFsNdbz93Brio0VfY8tfMU3+vd+qkkCALUGgEVGgHlag3K1QIq1BqUawRUFOdBmnEetrcuQHbrHBSZCVDkJsFGU1ZtPxqJLbJcg3E84FlccLhPL9zk3RF8yioaNxmtRAJ4ONweeOS6AmNPJzEM3f5Ul6u9nXn/TgmC+OTc7UGyNA+ImAHcM8x87TCF7CvAT7OBa0cBtar659oC99sfXvAOaRZPfTIkmQFDEmk0ApIyCvHXtWxdMErJrn7rpLWzHOHt3BEW6IHO3k64VaDC9ZwSXM8prvxvCW7mltQZpmRSG/i5KdDW/c4AJf7s5WT5EJVfWo7EyjB04aYYSJIyCqBWq9HP5jzGSg9hqM1fkEvEf/WrYYO/nfsivf0YuAeEoOPvs+GcLdY8nA6Ygl/8piGvFLqeg7w7ehVKy43/UnVzsEOwn4suEHXzdUUHL0fYGiqAvXURWD8KKLgpFho//YP5J0utUIm3JO/smSgrMLh6pqwtkmyCEF/uj+MlbZCgaYcMuMFQIbGnowwSCVCuFgNRhVpAuUYDQRDgjRwE21xFN10NzjW0s0k3eMx8wUGvlytBE4gkoS3KGzCXukQCvXCr97Mu/Fb1LLrY28HNwQ6ejjK4Ocjumt7YZkNdIU4orDx7W/g7KwZ9Q1z99XucfELFSYjNeJuYIckMGJLuPiVlasSn5uLktWz8dS0Hp67lVKtrkEiAe7ydERbojvB27ggP9EBbd/s660Qq1BqkF6hwPbsqOKXmFOuClDKvtM7xUGRSG7R2kVfrQXG54714u0r/c0eZtEG1LIIgIC2/FBdu3FbQrMxDanaJ3npBEiXGSH/D47ZH4IMs3fJSj3tg2ysatveOB5xa3/aLUAH75lXVaAREiDOc1zBmjqpCjQJdaKoKT+JtGv3bMhqNgHtu6yXydVXU75xvxgPfjAaKs8RakugdgEszmQxbowFyr+qHJuVZMcwZoJJ7It2hE/6xCcLp8gD8XuiH+GJPaGADKdQIkih1hebaUOQpMRzClPBEkiQISTbtcUXaHsl27ZEl9YGdnQ1sbWxgJ5XATmoDW6kN5LY2Bm+V6ocdW7ja28FR1vDbp9TMCAKQf1M/NCnPivVphihc9UOTT6jYC9VET30yJJkBQ1LLl5FfKt42u5qDk9eyceFmfrXeHns7KXoGuCEs0B1hge7oGeAOV3vT1xRUqDVIyy8Vw9NtQaoqRJXUOShbbaQ2EjgrbKt/kd0WrpwUtlDmlerqeHJqqAHp5CrgKeeTGKL6BW0KzlR9oHADQseKk4r63lv7vxzPbxNnfi8rABw8xad9Og42/gSNde0P4NtxYu2FX0/gya2Ao6f529FQRZn6dUFp54DMS4BQvedNsLWHytkfsvxrsDFw20SQSCG06gz4hMJGW2zMwTLJGCW5QPqF2/5snqm7wL3LQ2KRvwkxJJkBQ1LLoNEIyC4uQ1peKTIKxBByOiUXf13LrtYrAgA+LgqEtXNHeKDYS9TV19nw7RkzK1droMwtxa1CVbWiVkPFrgW31YOUq437X4DURoJOrZ3EnhlfJ/S1uYBON3+E7NJPQEXl705iA3QcAtz7BHDPiIYVcmZdBrZMqhxPRyLOeP7AXNPMel4f/+wHNj0lnktgP2DiJkBhxX/Xy0vEGeRvv12Xfl5/sESZk/6o4b7dAa+ugJ3Ccu2mlk1b4K7tBb2zwL3HE8BjK016SIYkM2BIav5Ky9W6eYAMzQmkDUY1hQSJBOji4yIGonZiT1Ebt7pvnVkTQRBQWq65LUAZfnpIu9zTSVZZx+OKTt5OUBRcA+I3itM55KVW7bhVZ3Heq+7jG3drqry0coLPteL7dpHiDOjOPo078bok/AB8P1X8F27HB4Fx65vHhKemplGLBbg5VwGP9oB7kFU9yk0tlK7A/Rzg5A3432fS3TMkmQFDkjg54bWsIlxKL0RSegEuZYj/zS4qg73eyLBS2NvZ3jFarPS20WJtdSPK2leOHmt/x9D6t48oq9EIyCxSIT2vak6g20OQ9ueGjIPSyqlqQLTgNq4ID3RHzwA3OCus4HFcc1MVitM1xH8rTt+gJXcFQseI4ahNmGkLMc99D/w4U5yx3dFLDErtHzDd/m8X/y3ww4viraluo8RbfXfTiNhELVxDvr+b53CY1KyoKwfZu5ReIIah9EIkZRTi8q3CRj+y2xDauYlKytT1fqze3k6qG/21+oiw4n+9nOSQ2fJfz7XSaICUo2KAuLADKC+q/EACdPiXGIy6PATY2de2F+OFPg749hBnRc+4ID5pNvBNcWZ0U95+O/4lsOcN8eee0eJAeea6vUdEzQ57kozUEnuSNBoBqTnFuJReqBeILt8qhKqGMKSws0HH1k7o3NoZnbyd0dnbCd4uCqgq1JUzW6vvmLm6Qm8W6+LKz0q0s2CXa1BSVlH1eQ2zXNtIgFZOVSPe3h6CfCrnBmrtooCLwrZF3R4zu5xrwJlNwJlvxVsyWh4dxDqjHhPNOzpweYkYYk6tF98HDRR7lW5/Qs4YggD89hFwYJH4vs8LwND3m99cYkTUaLzdZgbWHJI0GgE3cktwSdsrlF6ASxkF+CejsMZxZ+S2lWHI2xmdvMVQ1NnbGW3dm34eqbIKzW1BqwL2Mim8nOTNomC6RSorBhJ3irO0J/9WtVzmDASPAno+Bfj3tmyAOLMJ+OkVsejYyRsYEwsERRq3L0EQp1o4+rn4fuAc8WkaBiSiFokhyQysNSTtu5CG1747g4Iapl+Q2dqgg5cTOntXBqLKYOTv4cBB2loyQQBSjwOnvxFvp90+QGHQQPF2WteRzat4+dZF8fbbrUTxKboH/gNEvtqwwmONGtj1alVh+ND3gb4vNk17iahZYE0S1WjXWSUKVBWQSW3Q3ssRnStvkYm3ypwRwDB0d8m7Lj6ZFv+t+JSTlns7MRj1mCCOhtsced0DPPsLsPt1sdfrwCKxbmr06vpNnKouB7ZPB85/D0ACPPIZ0OvpJm82EVkPhqS7TE6xOLdSzOhQjAlr2/gdah8hVp6pGt+iQNn4/bZUUpk48aNuWP4QwN7dvG0oLwH+3iX2Gl05CKCyM9nOEQh+TKw1CoywjttNMkdg1ApxHKNdrwKXfwW+6C/OpB4YUfN25SXAlsnApb3iHFOjVwMho83WbCKyDgxJd5nsIjEkeTga8UhzWTGQkVg5gm/loF/pF/QHo6O6KePF3hst1wD9SSB9QsX5jUwZUgQBuP6X2ONyfpv+TOSB/cVRsLs+AsidTHdMc+r5pDgi9pZJ4sjS6x4GBs0D+r1S/fabqgDYOBG4ehiwVQDjvgY6R1mm3UTUrDEk3WVyK6eScK8rJBVl6s9UrTwrTmJoYFoD2NqLPSLaL3j3dmKNCFWnKqwclr8yaOamAHmVr4u7qtZTuFWfBNLrHkDawHGb8pXA2U3i7bTMS1XLXQMqn06bAHgEmeTULM67G/DsAWDXbODsZuCXheK0Io99WTWVSHE2sOFx4MZJcXTpJzYD7fpbtt1E1GwxJN1ldD1JDpUhSTtB5p0zi9cwQSYcWlX2eHSv+hL37MCxZBqi68NVP5fkilND3P77v5UIlOaKPR1XD1etW+1WXXfAO7j6VBnlpcClPcDpDcDlX6qCra090O1RsdclsH/LHFlZ7iSGosB+4lAB/8QBX0aKt9/cg4CvHxPHWbJ3B57aKg56SURUAz7dZiRrfLqtpEyN8Le3Y7j0T7zfWw1Z5gUg7bz+k0y38+hw222gylDk5G0dtSrWrEIlPrmVdkdwVeUbXt89qCo4FaYD57aIIUsroK/Ya9RtlHXPPdZQaefF229Z/wASqTiWUoEScPIBoreLPU9EdNfhEABmYI0h6dal4yj6JhrtbNL1P5DKxS8MvR6KboDc2TINpeoEQRzM8fbQlHYWyL9heH2XNuJAj/c+Ifb03a1UBeJ0Jue3iu/dAoCnfxDnKSOiuxJDkhlYVUgSBOCvWGj2zIWNpgxpaAWfvhPEMOTbHfDsBEh559UqFWUB6bfVjUll4vxpQQN5C1RLEMSC9WtHgX/NM+8I4UTU7DAkmYHVhKTSfPFf0he2AQDi1GH40u1VfP/qQxZuGBERkflxMEkSpZ0TRyTOvgzY2OJ8t1fx7F/d0cfZw9ItIyIiavYYkloiQQBOfQXseROoKAVc2gJj1+JkamsAF4wbI4mIiOguw5DU0qgKxYk/z30nvu80FHjsC8DBA9l/i+PkuDkwJBEREdWFIaklSb8g3l7LShIfeR78NhAxQzcejnZKEg+GJCIiojoxJLUEgiDOw7X7daCiBHD2q5y7qq/eajn1HW2biIiIGJKsXlmROLGndi6wjkMqp2GoPgt6jm7etgZObUFERHQXYkiyZhl/iyMK3/pbnCtt0FuGJ/SspJ2SxJ2324iIiOrEkGSt4jeKE3mWF4vTLDweW+dEndqaJIYkIiKiujEkWZuyYmDP62INEgC0/xcwejXg5FXnprrJbVmTREREVCeGJGty65J4ey0jQby99sBcIPLVek0/UVKmhqpCnA2ehdtERER1Y0iyFme/A36cBZQXAY6txdtrQQPqvXl25a02mdQGjjLO6UVERFQXhqTmrrxEHDn71Ffi+3aRwJhYwNm7QbvRPtnm7mgHiURi6lYSERG1OIYfgzKjFStWICgoCAqFAmFhYTh8+HCt62/YsAE9evSAg4MDfH19MWXKFGRlZemts3XrVnTr1g1yuRzdunXD9u3bG31ci8j8B/i/BysDkgQY+Cbw9A8NDkgAn2wjIiJqKIuGpM2bN2PWrFmYN28eTp8+jcjISAwfPhwpKSkG1z9y5AiefvppTJ06FRcuXMCWLVtw4sQJTJs2TbfOH3/8gfHjxyM6OhpnzpxBdHQ0xo0bh+PHjxt9XIs4vxVYNRBIPwc4egHR24F//ade9UeG8Mk2IiKihpEIgiBY6uC9e/dGr169sHLlSt2yrl27YtSoUYiJiam2/kcffYSVK1fi8uXLumWff/45lixZgtTUVADA+PHjkZ+fjz179ujWGTZsGNzd3bFx40ajjmtIfn4+XF1dkZeXBxcXl4adeG3KS4F9c4G/1ojvA/sDY/4PcPFt1G7X/Z6MBT8m4KFQX/zvyV4maCgREZH1acj3t8V6ksrKynDy5ElERUXpLY+KisLRo0cNbhMREYHr169j9+7dEAQB6enp+P777/HQQw/p1vnjjz+q7XPo0KG6fRpzXABQqVTIz8/XezWJQx9UBaTI18Tba40MSACQrZuShKNtExER1YfFQlJmZibUajW8vfXra7y9vZGWlmZwm4iICGzYsAHjx4+HTCaDj48P3Nzc8Pnnn+vWSUtLq3WfxhwXAGJiYuDq6qp7+fv7N+h8663/K0Db+4GntgKD5wNS09TW66Yk4e02IiKierF44fadT1oJglDj01cJCQmYMWMG3n77bZw8eRJ79+5FcnIypk+f3uB9NuS4ADB37lzk5eXpXtrbeyancAGm/izOwWZC2iEA3BiSiIiI6sViQwC0atUKUqm0Wu9NRkZGtV4erZiYGPTr1w+vv/46AKB79+5wdHREZGQkFi1aBF9fX/j4+NS6T2OOCwByuRxyubzB52mUJnhEP4ejbRMRETWIxXqSZDIZwsLCEBcXp7c8Li4OERERBrcpLi6GzR2Tt0ql4tNe2vrzvn37Vtvnzz//rNunMcdtCXJ0NUkMSURERPVh0cEkZ8+ejejoaISHh6Nv375YtWoVUlJSdLfP5s6dixs3bmD9+vUAgJEjR+LZZ5/FypUrMXToUCiVSsyaNQv3338//Pz8AAAzZ87EgAED8MEHH+DRRx/FDz/8gP379+PIkSP1Pm5LxJokIiKihrFoSBo/fjyysrKwcOFCKJVKhISEYPfu3QgMDAQAKJVKvbGLJk+ejIKCAixfvhyvvvoq3NzcMGjQIHzwwQe6dSIiIrBp0ya89dZbmD9/Pjp06IDNmzejd+/e9T5uSyMIgq4miU+3ERER1Y9Fx0myZk02TlITKFJVIPidfQCAC+8OhaOcs9EQEdHdySrGSSLz0U5JIrO1gQMntyUiIqoXhqS7QG5l0baHg4yT2xIREdUTQ9JdoKoeiUXbRERE9cWQdBeoGiOJRdtERET1xZB0F9DWJHG0bSIiovpjSLoL5BRzjCQiIqKGYki6C+SwJomIiKjBGJLuAjlF2qfbWJNERERUXwxJdwFtTRJ7koiIiOqPIekuoLvdxpokIiKiemNIugtk64YAYEgiIiKqL4akFk4QBN2I27zdRkREVH8MSS1cUZkaZWoNAA4BQERE1BAMSS2cdrRthZ0N7Dm5LRERUb0xJLVwuifb2ItERETUIAxJLVw2n2wjIiIyCkNSC5dbzCfbiIiIjMGQ1MJlF/HJNiIiImMwJLVw2sJtTklCRETUMAxJLZy2JsmNNUlEREQNwpDUwuVwtG0iIiKjMCS1cLp52xiSiIiIGoQhqYXLqSzc5mjbREREDcOQ1MLpxklyZOE2ERFRQzAktWCCIOhqkjiYJBERUcMwJLVgBaoKVGgEAAxJREREDcWQ1ILlVtYj2dtJObktERFRAzEktWDZnJKEiIjIaAxJLZiuHolF20RERA3GkNSCZbNom4iIyGgMSS2YbiBJhiQiIqIGY0hqwXJYk0RERGQ0hqQWLLvy6Tb2JBERETUcQ1ILVjW5LQu3iYiIGoohqQXTDgHgxp4kIiKiBmNIasGqepIYkoiIiBqKIakFyylmTRIREZGxGJJaKEEQ+HQbERFRIzAktVD5pRVQV05u6+bAwm0iIqKGsnhIWrFiBYKCgqBQKBAWFobDhw/XuO7kyZMhkUiqvYKDg3XrPPDAAwbXeeihh3TrLFiwoNrnPj4+TXqe5qatR3KQSaGw4+S2REREDWXRkLR582bMmjUL8+bNw+nTpxEZGYnhw4cjJSXF4PrLli2DUqnUvVJTU+Hh4YGxY8fq1tm2bZveOufPn4dUKtVbBwCCg4P11jt37lyTnqu5ZXO0bSIiokaxteTBP/74Y0ydOhXTpk0DAHz66afYt28fVq5ciZiYmGrru7q6wtXVVfd+x44dyMnJwZQpU3TLPDw89LbZtGkTHBwcqoUkW1vbFtd7dLtc1iMRERE1isV6ksrKynDy5ElERUXpLY+KisLRo0frtY/Y2FgMGTIEgYGBta4zYcIEODo66i1PSkqCn58fgoKCMGHCBFy5cqXWY6lUKuTn5+u9mjPdaNsMSUREREaxWEjKzMyEWq2Gt7e33nJvb2+kpaXVub1SqcSePXt0vVCG/Pnnnzh//ny1dXr37o3169dj3759WL16NdLS0hAREYGsrKwa9xUTE6PryXJ1dYW/v3+dbbQk3RhJLNomIiIyisULtyUSid57QRCqLTNk3bp1cHNzw6hRo2pcJzY2FiEhIbj//vv1lg8fPhxjxoxBaGgohgwZgl27dgEAvvrqqxr3NXfuXOTl5eleqampdbbRkjjaNhERUeNYrCapVatWkEql1XqNMjIyqvUu3UkQBKxZswbR0dGQyQyHgOLiYmzatAkLFy6ssy2Ojo4IDQ1FUlJSjevI5XLI5fI699VccLRtIiKixrFYT5JMJkNYWBji4uL0lsfFxSEiIqLWbQ8dOoR//vkHU6dOrXGd7777DiqVCk899VSdbVGpVEhMTISvr2/9Gm8FtANJsiaJiIjIOBZ9um327NmIjo5GeHg4+vbti1WrViElJQXTp08HIN7iunHjBtavX6+3XWxsLHr37o2QkJAa9x0bG4tRo0bB09Oz2mevvfYaRo4ciYCAAGRkZGDRokXIz8/HpEmTTHuCFpRTWbjtwdttRERERrFoSBo/fjyysrKwcOFCKJVKhISEYPfu3bqn1ZRKZbUxk/Ly8rB161YsW7asxv1eunQJR44cwc8//2zw8+vXr2PixInIzMyEl5cX+vTpg2PHjtX6lJy10Y2T5MjCbSIiImNIBEEQLN0Ia5Sfnw9XV1fk5eXBxcXF0s2pJuy9OGQVlWHPzEh09W1+7SMiIrKEhnx/W/zpNjI9jYaT2xIRETUWQ1ILlF9ajsq5bTm5LRERkZEYklqgnGKxaNtJbgu5LSe3JSIiMgZDUguUXcSibSIiosZiSGqBtANJuvPxfyIiIqMxJLVAusf/GZKIiIiMxpDUAnFKEiIiosZjSGqBtIXb7EkiIiIyHkNSC1TVk8TCbSIiImMxJLVA2pokN/YkERERGY0hqQViTRIREVHjMSS1QHy6jYiIqPEYklqg3MrCbfYkERERGY8hqYVRawTkFnPEbSIiosZiSGph8ktum9zWnj1JRERExmJIamG09UjOclvIbHl5iYiIjMVv0RZGN28b65GIiIgahSGphdGNts2QRERE1CgMSS2MbowkBxZtExERNQZDUgvDMZKIiIhMgyGphWFNEhERkWkwJLUw2ZyShIiIyCQYkloYXeE2b7cRERE1CkNSC5NTrO1JYuE2ERFRYzAktTDamiQ39iQRERE1CkNSC5NdzJokIiIiU2BIakHUGgF5JaxJIiIiMgWGpBYkr6QcgnZyWw4mSURE1ChGhaSDBw+auBlkCtrH/10UtrCTMv8SERE1hlHfpMOGDUOHDh2waNEipKammrpNZCTtk20cSJKIiKjxjApJN2/exMyZM7Ft2zYEBQVh6NCh+O6771BWVmbq9lEDaHuSWI9ERETUeEaFJA8PD8yYMQOnTp3CX3/9hXvuuQcvvvgifH19MWPGDJw5c8bU7aR6yOFo20RERCbT6MKVe++9F3PmzMGLL76IoqIirFmzBmFhYYiMjMSFCxdM0UaqJ462TUREZDpGh6Ty8nJ8//33GDFiBAIDA7Fv3z4sX74c6enpSE5Ohr+/P8aOHWvKtlIdONo2ERGR6dgas9HLL7+MjRs3AgCeeuopLFmyBCEhIbrPHR0dsXjxYrRr184kjaT60dUk8XYbERFRoxkVkhISEvD5559jzJgxkMkMfyH7+fnhwIEDjWocNUwOC7eJiIhMxqiQ9Msvv9S9Y1tbDBw40Jjdk5G0U5IwJBERETWeUTVJMTExWLNmTbXla9aswQcffNDoRpFxcisLt/l0GxERUeMZFZK+/PJLdOnSpdry4OBgfPHFF41uFBknu4iF20RERKZiVEhKS0uDr69vteVeXl5QKpWNbhQ1XIVaw8ltiYiITMiokOTv74/ff/+92vLff/8dfn5+DdrXihUrEBQUBIVCgbCwMBw+fLjGdSdPngyJRFLtFRwcrFtn3bp1BtcpLS01+rjWILcyIAGAqz17koiIiBrLqJA0bdo0zJo1C2vXrsW1a9dw7do1rFmzBq+88gqeffbZeu9n8+bNmDVrFubNm4fTp08jMjISw4cPR0pKisH1ly1bBqVSqXulpqbCw8Oj2nhMLi4ueusplUooFAqjj2sNtE+2udrbwZaT2xIRETWeYASNRiO88cYbgkKhEGxsbAQbGxvBwcFBePfddxu0n/vvv1+YPn263rIuXboIc+bMqdf227dvFyQSiXD16lXdsrVr1wqurq4mP25paamQl5ene6WmpgoAhLy8vHq1takdv5IlBL75k/DAhwcs3RQiIqJmKy8vr97f30Z1OUgkEnzwwQe4desWjh07hjNnziA7Oxtvv/12vfdRVlaGkydPIioqSm95VFQUjh49Wq99xMbGYsiQIQgMDNRbXlhYiMDAQLRt2xYPP/wwTp8+3ejjxsTEwNXVVffy9/evVxvNpWpyW95qIyIiMoVG3ZdxcnLCfffdh5CQEMjl8gZtm5mZCbVaDW9vb73l3t7eSEtLq3N7pVKJPXv2YNq0aXrLu3TpgnXr1mHnzp3YuHEjFAoF+vXrh6SkpEYdd+7cucjLy9O9UlNT63uqZlE1JQmLtomIiEzBqMEkAeDEiRPYsmULUlJSUFZWpvfZtm3b6r0fiUSi914QhGrLDFm3bh3c3NwwatQoveV9+vRBnz59dO/79euHXr164fPPP8dnn31m9HHlcnmDg6A5aXuS3PhkGxERkUkY1ZO0adMm9OvXDwkJCdi+fTvKy8uRkJCAX3/9Fa6urvXaR6tWrSCVSqv13mRkZFTr5bmTIAhYs2YNoqOja5wWRcvGxgb33XefriepMcdtznKK2JNERERkSkaFpPfffx+ffPIJfvrpJ8hkMixbtgyJiYkYN24cAgIC6rUPmUyGsLAwxMXF6S2Pi4tDRERErdseOnQI//zzD6ZOnVrncQRBQHx8vG5cp8YctznLKeYYSURERKZk1O22y5cv46GHHgIg3oYqKiqCRCLBK6+8gkGDBuHdd9+t135mz56N6OhohIeHo2/fvli1ahVSUlIwffp0AGId0I0bN7B+/Xq97WJjY9G7d2+EhIRU2+e7776LPn36oFOnTsjPz8dnn32G+Ph4/O9//6v3ca1RVU0SC7eJiIhMwaiQ5OHhgYKCAgBAmzZtcP78eYSGhiI3NxfFxcX13s/48eORlZWFhQsXQqlUIiQkBLt379Y9raZUKquNXZSXl4etW7di2bJlBveZm5uL5557DmlpaXB1dUXPnj3x22+/4f7776/3ca1R1dNt7EkiIiIyBYkgCEJDN3riiScQHh6O2bNn47///S+WLVuGRx99FHFxcejVq1eDCretVX5+PlxdXZGXlwcXFxdLNwcDPzyAa1nF2DK9L+5r52Hp5hARETVLDfn+Nqonafny5bppPubOnQs7OzscOXIEo0ePxvz5843ZJTUSe5KIiIhMq8EhqaKiAj/++COGDh0KQHx67I033sAbb7xh8sZR/ZSrNSgorQDAp9uIiIhMpcFPt9na2uL555+HSqVqivaQEXIrn2yTSDi5LRERkakYNQRA79699ab6IMvSPtnmZm8HqU3dA3ESERFR3YyqSXrhhRfw6quv4vr16wgLC4Ojo6Pe5927dzdJ46h+WI9ERERkekaFpPHjxwMAZsyYoVsmkUh0U3uo1WrTtI7qRTvatjvrkYiIiEzGqJCUnJxs6nZQI3C0bSIiItMzKiRZ86CLLRFH2yYiIjI9o0LSndOE3Onpp582qjFknGzebiMiIjI5o0LSzJkz9d6Xl5ejuLgYMpkMDg4ODElmlsPCbSIiIpMzagiAnJwcvVdhYSEuXryI/v37Y+PGjaZuI9UhW3u7jSGJiIjIZIwKSYZ06tQJixcvrtbLRE1PV7jN221EREQmY7KQBABSqRQ3b9405S6pHrS321i4TUREZDpG1STt3LlT770gCFAqlVi+fDn69etnkoZR/bEmiYiIyPSMCkmjRo3Sey+RSODl5YVBgwZh6dKlpmgX1VNZhQYFKnFyW4YkIiIi0zEqJGk0GlO3g4yUW1m0bSMBXDi5LRERkcmYtCaJzE9btO3mIOPktkRERCZkVEh6/PHHsXjx4mrLP/zwQ4wdO7bRjaL6q5rclr1IREREpmRUSDp06BAeeuihasuHDRuG3377rdGNovqrmpKE9UhERESmZFRIKiwshExW/UvZzs4O+fn5jW4U1Z+2J8mNRdtEREQmZVRICgkJwebNm6st37RpE7p169boRlH96cZIYkgiIiIyKaOebps/fz7GjBmDy5cvY9CgQQCAX375BRs3bsSWLVtM2kCqHUfbJiIiahpGhaRHHnkEO3bswPvvv4/vv/8e9vb26N69O/bv34+BAweauo1Ui6qaJBZuExERmZJRIQkAHnroIYPF22Re2Rxtm4iIqEkYVZN04sQJHD9+vNry48eP46+//mp0o6j+tD1JDElERESmZVRIevHFF5Gamlpt+Y0bN/Diiy82ulFUf7qeJNYkERERmZRRISkhIQG9evWqtrxnz55ISEhodKOo/nIrC7c5ThIREZFpGRWS5HI50tPTqy1XKpWwtTW6zIkaSFWhRmHl5LYcAoCIiMi0jApJDz74IObOnYu8vDzdstzcXPznP//Bgw8+aLLGUe20vUhSGwmcFQynREREpmTUN+vSpUsxYMAABAYGomfPngCA+Ph4eHt74+uvvzZpA6lmutG27e1gw8ltiYiITMqokNSmTRucPXsWGzZswJkzZ2Bvb48pU6Zg4sSJsLPjeD3mksOibSIioiZj9D0aR0dH9O/fHwEBASgrE7+s9+zZA0AcbJKanna0bdYjERERmZ5RIenKlSt47LHHcO7cOUgkEgiCAImk6naPWq02WQOpZtnaMZI42jYREZHJGVW4PXPmTAQFBSE9PR0ODg44f/48Dh06hPDwcBw8eNDETaSa6Ca35e02IiIikzOqJ+mPP/7Ar7/+Ci8vL9jY2EAqlaJ///6IiYnBjBkzcPr0aVO3kwzQFW7zdhsREZHJGdWTpFar4eTkBABo1aoVbt68CQAIDAzExYsXTdc6qpVucluGJCIiIpMzqicpJCQEZ8+eRfv27dG7d28sWbIEMpkMq1atQvv27U3dRqqBtnCbT7cRERGZnlEh6a233kJRUREAYNGiRXj44YcRGRkJT09PbN682aQNpJpV1SSxcJuIiMjUjApJQ4cO1f3cvn17JCQkIDs7G+7u7npPuVHT0k1uy9ttREREJmdUTZIhHh4eRgWkFStWICgoCAqFAmFhYTh8+HCN606ePBkSiaTaKzg4WLfO6tWrERkZCXd3d7i7u2PIkCH4888/9fazYMGCavvw8fFpcNstTVuTxJBERERkeiYLScbYvHkzZs2ahXnz5uH06dOIjIzE8OHDkZKSYnD9ZcuWQalU6l6pqanw8PDA2LFjdescPHgQEydOxIEDB/DHH38gICAAUVFRuHHjht6+goOD9fZ17ty5Jj1XUystV6O4TByPijVJREREpmfRWVE//vhjTJ06FdOmTQMAfPrpp9i3bx9WrlyJmJiYauu7urrC1dVV937Hjh3IycnBlClTdMs2bNigt83q1avx/fff45dffsHTTz+tW25ra9ug3iOVSgWVSqV7n5+fX+9tm8Ltk9u6cHJbIiIik7NYT1JZWRlOnjyJqKgoveVRUVE4evRovfYRGxuLIUOGIDAwsMZ1iouLUV5eDg8PD73lSUlJ8PPzQ1BQECZMmIArV67UeqyYmBhdSHN1dYW/v3+92thUbq9HYh0YERGR6VksJGVmZkKtVsPb21tvube3N9LS0urcXqlUYs+ePbpeqJrMmTMHbdq0wZAhQ3TLevfujfXr12Pfvn1YvXo10tLSEBERgaysrBr3M3fuXOTl5eleqampdbaxKenGSOKTbURERE3C4vdp7uwFuXMeuJqsW7cObm5uGDVqVI3rLFmyBBs3bsTBgwehUCh0y4cPH677OTQ0FH379kWHDh3w1VdfYfbs2Qb3JZfLIZfL62yXuXC0bSIioqZlsZDUqlUrSKXSar1GGRkZ1XqX7iQIAtasWYPo6GjIZIZDwkcffYT3338f+/fvR/fu3Wvdn6OjI0JDQ5GUlNSwk7AgjrZNRETUtCx2u00mkyEsLAxxcXF6y+Pi4hAREVHrtocOHcI///yDqVOnGvz8ww8/xHvvvYe9e/ciPDy8zraoVCokJibC19e3/idgYTlFHG2biIioKVn0dtvs2bMRHR2N8PBw9O3bF6tWrUJKSgqmT58OQKwDunHjBtavX6+3XWxsLHr37o2QkJBq+1yyZAnmz5+Pb7/9Fu3atdP1VDk5Oenmm3vttdcwcuRIBAQEICMjA4sWLUJ+fj4mTZrUxGdsOqxJIiIialoWDUnjx49HVlYWFi5cCKVSiZCQEOzevVv3tJpSqaw2ZlJeXh62bt2KZcuWGdznihUrUFZWhscff1xv+TvvvIMFCxYAAK5fv46JEyciMzMTXl5e6NOnD44dO1brU3LNDUfbJiIialoSQRAESzfCGuXn58PV1RV5eXlwcXEx+/GjY4/jcFImlo7tgTFhbc1+fCIiImvUkO9vi464TcbL1k1uy54kIiKipsCQZKW0I26zcJuIiKhpMCRZKV1PEmuSiIiImgRDkhUqKVOjpFw7uS2fbiMiImoKDElWSPv4v62NBE5yiw+aTkRE1CIxJFkh3eP/jpzcloiIqKkwJFkhbdE265GIiIiaDkOSFcou1vYksR6JiIioqTAkWaEcjpFERETU5BiSrJC2JsmNt9uIiIiaDEOSFdJNbsuQRERE1GQYkqxQDkfbJiIianIMSVaoqiaJhdtERERNhSHJCunGSeLtNiIioibDkGSFtDVJDElERERNhyHJygiCUDW5LWuSiIiImgxDkpUpKVdDVaEBwMJtIiKipsSQZGW0T7bJpDZwlEkt3BoiIqKWiyHJyuQUVU1JwsltiYiImg5DkpXhk21ERETmwZBkZfhkGxERkXkwJFkZPtlGRERkHgxJVqZqShKOtk1ERNSUGJKsjG5KEt5uIyIialIMSVYmu7ImyY0hiYiIqEkxJFmZHNYkERERmQVDkpXRDQHAkERERNSkGJKsTG5l4TZrkoiIiJoWQ5IVEQRBV5PEp9uIiIiaFkOSFSkuU6NMO7kte5KIiIiaFEOSFdHWI8lsbeDAyW2JiIiaFEOSFdFOSeLhIOPktkRERE2MIcmKVI22zVttRERETY0hyYpUjZHEom0iIqKmxpBkRbQ1SRxtm4iIqOkxJFmR22uSiIiIqGkxJFkRjrZNRERkPgxJVqRqtG3WJBERETU1hiQrwp4kIiIi87F4SFqxYgWCgoKgUCgQFhaGw4cP17ju5MmTIZFIqr2Cg4P11tu6dSu6desGuVyObt26Yfv27Y06bnOhrUniaNtERERNz6IhafPmzZg1axbmzZuH06dPIzIyEsOHD0dKSorB9ZctWwalUql7paamwsPDA2PHjtWt88cff2D8+PGIjo7GmTNnEB0djXHjxuH48eNGH7e5yNYNAcCQRERE1NQkgiAIljp479690atXL6xcuVK3rGvXrhg1ahRiYmLq3H7Hjh0YPXo0kpOTERgYCAAYP3488vPzsWfPHt16w4YNg7u7OzZu3GiS4wJAfn4+XF1dkZeXBxcXl3pt0xiCIKDzW3tQrhbw+5xBaONm3+THJCIiamka8v1tsZ6ksrIynDx5ElFRUXrLo6KicPTo0XrtIzY2FkOGDNEFJEDsSbpzn0OHDtXt09jjqlQq5Ofn673MqahMjXK1mGc5BAAREVHTs1hIyszMhFqthre3t95yb29vpKWl1bm9UqnEnj17MG3aNL3laWlpte7T2OPGxMTA1dVV9/L396+zjaakHW1bYWcDe05uS0RE1OQsXrh950StgiDUa/LWdevWwc3NDaNGjTJqnw097ty5c5GXl6d7paam1tlGU9LVI7EXiYiIyCxsLXXgVq1aQSqVVuu9ycjIqNbLcydBELBmzRpER0dDJtMPDT4+PrXu09jjyuVyyOXyOs+rqWQXc0oSIiIic7JYT5JMJkNYWBji4uL0lsfFxSEiIqLWbQ8dOoR//vkHU6dOrfZZ3759q+3z559/1u2zMce1pBw+2UZERGRWFutJAoDZs2cjOjoa4eHh6Nu3L1atWoWUlBRMnz4dgHiL68aNG1i/fr3edrGxsejduzdCQkKq7XPmzJkYMGAAPvjgAzz66KP44YcfsH//fhw5cqTex22OcipH2+ZAkkREROZh0ZA0fvx4ZGVlYeHChVAqlQgJCcHu3bt1T6splcpqYxfl5eVh69atWLZsmcF9RkREYNOmTXjrrbcwf/58dOjQAZs3b0bv3r3rfdzmSNeTxClJiIiIzMKi4yRZM3OPk/Sf7efw7fEUzBrSCbOGdG7y4xEREbVEVjFOEjWMtieJU5IQERGZB0OSleDktkRERObFkGQlcisLtzlOEhERkXkwJFkJ7ThJ7o4s3CYiIjIHhiQrIAgCx0kiIiIyM4YkK1CgqkCFRnwIkYXbRERE5sGQZAW0vUj2dlIo7Di5LRERkTkwJFkB7WjbvNVGRERkPgxJVkA3RhKLtomIiMyGIckKZHMgSSIiIrNjSLICOcUMSURERObGkGQFsvn4PxERkdkxJFkBbeE2e5KIiIjMhyHJClQNJMnCbSIiInNhSLICVVOSsCeJiIjIXBiSrEAOn24jIiIyO4YkK8Cn24iIiMyPIamZEwSBI24TERFZAENSM5dfWgF15eS2bg4s3CYiIjIXhqRmTluP5Cjj5LZERETmxJDUzGmfbHNjPRIREZFZMSQ1czkcbZuIiMgiGJKaOd1o2wxJREREZsWQ1MzpepJYtE1ERGRWDEnNHEfbJiIisgyGpGaOo20TERFZBkNSM5ddxJ4kIiIiS2BIauZytaNtsyeJiIjIrBiSmrmqmiQWbhMREZkTQ1Izx3GSiIiILIMhqRnTaATkFLNwm4iIyBIYkpqx/NJyVM5ty8ltiYiIzIwhqRnTjrbtJLeF3JaT2xIREZkTQ1IzVvX4P3uRiIiIzI0hqRmrmpKE9UhERETmxpDUjGkf/3djSCIiIjI7hqRmjI//ExERWY6tpRtANdMWbvPxfyIikVqtRnl5uaWbQc2YVCqFra0tJBJJo/fFkNSMVfUksXCbiKiwsBDXr1+HIAiWbgo1cw4ODvD19YVM1rhOBouHpBUrVuDDDz+EUqlEcHAwPv30U0RGRta4vkqlwsKFC/HNN98gLS0Nbdu2xbx58/DMM88AAB544AEcOnSo2nYjRozArl27AAALFizAu+++q/e5t7c30tLSTHhmjVc1JQl7kojo7qZWq3H9+nU4ODjAy8vLJL0E1PIIgoCysjLcunULycnJ6NSpE2xsjK8ssmhI2rx5M2bNmoUVK1agX79++PLLLzF8+HAkJCQgICDA4Dbjxo1Deno6YmNj0bFjR2RkZKCiokL3+bZt21BWVqZ7n5WVhR49emDs2LF6+wkODsb+/ft176XS5jcOkbYnibfbiOhuV15eDkEQ4OXlBXt7e0s3h5oxe3t72NnZ4dq1aygrK4NCoTB6XxYNSR9//DGmTp2KadOmAQA+/fRT7Nu3DytXrkRMTEy19ffu3YtDhw7hypUr8PDwAAC0a9dObx3tcq1NmzbBwcGhWkiytbWFj4+PCc/G9LI5JQkRkR72IFF9NKb3SG8/JtmLEcrKynDy5ElERUXpLY+KisLRo0cNbrNz506Eh4djyZIlaNOmDTp37ozXXnsNJSUlNR4nNjYWEyZMgKOjo97ypKQk+Pn5ISgoCBMmTMCVK1dqba9KpUJ+fr7eq6nlVhZu8+k2IiIi87NYT1JmZibUajW8vb31ltdWG3TlyhUcOXIECoUC27dvR2ZmJl544QVkZ2djzZo11db/888/cf78ecTGxuot7927N9avX4/OnTsjPT0dixYtQkREBC5cuABPT0+Dx46JialWx9SU1BoBucUccZuIiMhSLD5O0p1dp4Ig1NidqtFoIJFIsGHDBtx///0YMWIEPv74Y6xbt85gb1JsbCxCQkJw//336y0fPnw4xowZg9DQUAwZMkRX0P3VV1/V2M65c+ciLy9P90pNTW3oqTZIfknV5La83UZERGR+FgtJrVq1glQqrdZrlJGRUa13ScvX1xdt2rSBq6urblnXrl0hCAKuX7+ut25xcTE2bdqkq3eqjaOjI0JDQ5GUlFTjOnK5HC4uLnqvpqStR3KW28JOavEsS0REdNex2LevTCZDWFgY4uLi9JbHxcUhIiLC4Db9+vXDzZs3UVhYqFt26dIl2NjYoG3btnrrfvfdd1CpVHjqqafqbItKpUJiYiJ8fX2NOJOmoXuyjfVIRERkQhyMs/4s2kUxe/Zs/N///R/WrFmDxMREvPLKK0hJScH06dMBiLe4nn76ad36TzzxBDw9PTFlyhQkJCTgt99+w+uvv45nnnmm2iOhsbGxGDVqlMEao9deew2HDh1CcnIyjh8/jscffxz5+fmYNGlS055wA+hG22ZIIiKqRhAEFJdVWOTV0MEs9+7di/79+8PNzQ2enp54+OGHcfnyZd3n169fx4QJE+Dh4QFHR0eEh4fj+PHjus+1Dy0pFAq0atUKo0eP1n0mkUiwY8cOveO5ublh3bp1AICrV69CIpHgu+++wwMPPACFQoFvvvkGWVlZmDhxItq2bQsHBweEhoZi48aNevvRaDT44IMP0LFjR8jlcgQEBOC///0vAGDQoEF46aWX9NbPysqCXC7Hr7/+2qDfT3Nm0SEAxo8fj6ysLCxcuBBKpRIhISHYvXs3AgMDAQBKpRIpKSm69Z2cnBAXF4eXX34Z4eHh8PT0xLhx47Bo0SK9/V66dAlHjhzBzz//bPC4169fx8SJE5GZmQkvLy/06dMHx44d0x23OdCNtu3Aom0iojuVlKvR7e19Fjl2wsKhcJDV/+uzqKgIs2fPRmhoKIqKivD222/jscceQ3x8PIqLizFw4EC0adMGO3fuhI+PD06dOgWNRgMA2LVrF0aPHo158+bh66+/RllZma6OtiHefPNNLF26FGvXroVcLkdpaSnCwsLw5ptvwsXFBbt27UJ0dDTat2+P3r17AxA7KlavXo1PPvkE/fv3h1KpxN9//w0AmDZtGl566SUsXboUcrkcALBhwwb4+fnhX//6V4Pb11xJBI7vbpT8/Hy4uroiLy+vSeqTvjh0GYv3/I3Rvdrg43H3mnz/RETWpLS0FMnJyQgKCoJCoUBxWYXVhKQ73bp1C61bt8a5c+dw9OhRvPbaa7h69Wq1cf4AICIiAu3bt8c333xjcF8SiQTbt2/HqFGjdMvc3Nzw6aefYvLkybh69SqCgoLw6aefYubMmbW266GHHkLXrl3x0UcfoaCgAF5eXli+fLnB2l6VSgU/Pz+sXLkS48aNAwD07NkTo0aNwjvvvNOA30bTuPPPy+0a8v1t8WlJyDCOtk1EVDN7OykSFg612LEb4vLly5g/fz6OHTuGzMxMXS9RSkoK4uPj0bNnT4MBCQDi4+Px7LPPNrrN4eHheu/VajUWL16MzZs348aNG1CpVFCpVLoxBRMTE6FSqTB48GCD+5PL5XjqqaewZs0ajBs3DvHx8Thz5ky1W3/WjiGpmcrWTW7LkEREdCeJRNKo3hxzGjlyJPz9/bF69Wr4+flBo9EgJCQEZWVldU6xUtfnEomkWo2UocLsOwdUXrp0KT755BN8+umnCA0NhaOjI2bNmqWb1qs+U79MmzYN9957L65fv441a9Zg8ODBzapsxRT4bHkzpSvcZk8SEZHVysrKQmJiIt566y0MHjwYXbt2RU5Oju7z7t27Iz4+HtnZ2Qa37969O3755Zca9+/l5QWlUql7n5SUhOLi4jrbdfjwYTz66KN46qmn0KNHD7Rv315vGJxOnTrB3t6+1mOHhoYiPDwcq1evxrfffqubaL4lYUhqpnKKtT1JLNwmIrJW7u7u8PT0xKpVq/DPP//g119/xezZs3WfT5w4ET4+Phg1ahR+//13XLlyBVu3bsUff/wBAHjnnXewceNGvPPOO0hMTMS5c+ewZMkS3faDBg3C8uXLcerUKfz111+YPn067Ozq/t7o2LEj4uLicPToUSQmJuLf//633riFCoUCb775Jt544w2sX78ely9fxrFjx6rNYDFt2jQsXrwYarUajz32WGN/Xc0OQ1IzxZokIiLrZ2Njg02bNuHkyZMICQnBK6+8gg8//FD3uUwmw88//4zWrVtjxIgRCA0NxeLFiyGVinVPDzzwALZs2YKdO3fi3nvvxaBBg/SGB1i6dCn8/f0xYMAAPPHEE3jttdfg4OBQZ7vmz5+PXr16YejQoXjggQd0Qe3OdV599VW8/fbb6Nq1K8aPH4+MjAy9dSZOnAhbW1s88cQT1QqkWwI+3Wakpn667d6FPyO3uBw/vzIAnb2dTb5/IiJrUtvTSmQ5qampaNeuHU6cOIFevXpZujk6fLqtBVNrBOSVsCaJiIiap/LyciiVSsyZMwd9+vRpVgHJlHi7rRnKKymHtn/PjYNJEhFRM/P7778jMDAQJ0+exBdffGHp5jQZ9iQ1Q9rH/10UnNyWiIianwceeKDB07NYI34DN0NVT7bxVhsREZGlMCQ1Q9qeJDfWIxEREVkMQ1IzlMPRtomIiCyOIakZ4mjbRERElseQ1AxxtG0iIiLLY0hqhrQ1Se683UZERGQxDEnNEKckISIiAGjXrh0+/fRTSzfjrsWQ1AxlFzMkERERWRpDUjOUW1m4zafbiIjIWqnVamg0Gks3o1EYkpqh7CIWbhMR1UoQgLIiy7zqOdL0l19+iTZt2lQLCo888ggmTZqEy5cv49FHH4W3tzecnJxw3333Yf/+/Ub/Sj7++GOEhobC0dER/v7+eOGFF1BYWKi3zu+//46BAwfCwcEB7u7uGDp0KHJycgAAGo0GH3zwATp27Ai5XI6AgAD897//BQAcPHgQEokEubm5un3Fx8dDIpHg6tWrAIB169bBzc0NP/30E7p16wa5XI5r167hxIkTePDBB9GqVSu4urpi4MCBOHXqlF67cnNz8dxzz8Hb2xsKhQIhISH46aefUFRUBBcXF3z//fd66//4449wdHREQUGB0b+v+uC0JM1MhVrDyW2JiOpSXgy872eZY//nJiBzrHO1sWPHYsaMGThw4AAGDx4MAMjJycG+ffvw448/orCwECNGjMCiRYugUCjw1VdfYeTIkbh48SICAgIa3CwbGxt89tlnaNeuHZKTk/HCCy/gjTfewIoVKwCIoWbw4MF45pln8Nlnn8HW1hYHDhyAWq0GAMydOxerV6/GJ598gv79+0OpVOLvv/9uUBuKi4sRExOD//u//4Onpydat26N5ORkTJo0CZ999hkAYOnSpRgxYgSSkpLg7OwMjUaD4cOHo6CgAN988w06dOiAhIQESKVSODo6YsKECVi7di0ef/xx3XG0752dnRv8e2oIhqRmJrcyIAGAqz17koiIrJWHhweGDRuGb7/9VheStmzZAg8PDwwePBhSqRQ9evTQrb9o0SJs374dO3fuxEsvvdTg482aNUv3c1BQEN577z08//zzupC0ZMkShIeH694DQHBwMACgoKAAy5Ytw/LlyzFp0iQAQIcOHdC/f/8GtaG8vBwrVqzQO69BgwbprfPll1/C3d0dhw4dwsMPP4z9+/fjzz//RGJiIjp37gwAaN++vW79adOmISIiAjdv3oSfnx8yMzPx008/IS4urkFtMwZDUjOjfbLN1d4OtpzclojIMDsHsUfHUseupyeffBLPPfccVqxYAblcjg0bNmDChAmQSqUoKirCu+++i59++gk3b95ERUUFSkpKkJKSYlSzDhw4gPfffx8JCQnIz89HRUUFSktLUVRUBEdHR8THx2Ps2LEGt01MTIRKpdKFOWPJZDJ0795db1lGRgbefvtt/Prrr0hPT4darUZxcbHuPOPj49G2bVtdQLrT/fffj+DgYKxfvx5z5szB119/jYCAAAwYMKBRba0Pfgs3Mzks2iYiqptEIt7yssRLIql3M0eOHAmNRoNdu3YhNTUVhw8fxlNPPQUAeP3117F161b897//xeHDhxEfH4/Q0FCUlZU1+Ndx7do1jBgxAiEhIdi6dStOnjyJ//3vfwDE3h0AsLe3r3H72j4DxFt5ACDcVo+l3e+d+5Hc8fuZPHkyTp48iU8//RRHjx5FfHw8PD09dedZ17EBsTdp7dq1AMRbbVOmTKl2nKbAkNTM6AaSdOCtNiIia2dvb4/Ro0djw4YN2LhxIzp37oywsDAAwOHDhzF58mQ89thjCA0NhY+Pj64IuqH++usvVFRUYOnSpejTpw86d+6Mmzf1e9q6d++OX375xeD2nTp1gr29fY2fe3l5AQCUSqVuWXx8fL3advjwYcyYMQMjRoxAcHAw5HI5MjMz9dp1/fp1XLp0qcZ9PPXUU0hJScFnn32GCxcu6G4JNjWGpGZGVaGGo0zKniQiohbiySefxK5du7BmzRpdLxIAdOzYEdu2bUN8fDzOnDmDJ554wuhH5jt06ICKigp8/vnnuHLlCr7++mt88cUXeuvMnTsXJ06cwAsvvICzZ8/i77//xsqVK5GZmQmFQoE333wTb7zxBtavX4/Lly/j2LFjiI2N1bXV398fCxYswKVLl7Br1y4sXbq0Xm3r2LEjvv76ayQmJuL48eN48skn9XqPBg4ciAEDBmDMmDGIi4tDcnIy9uzZg7179+rWcXd3x+jRo/H6668jKioKbdu2Ner31GACGSUvL08AIOTl5TXJ/ssr1E2yXyIia1RSUiIkJCQIJSUllm5Kg1VUVAi+vr4CAOHy5cu65cnJycK//vUvwd7eXvD39xeWL18uDBw4UJg5c6ZuncDAQOGTTz6p13E+/vhjwdfXV7C3txeGDh0qrF+/XgAg5OTk6NY5ePCgEBERIcjlcsHNzU0YOnSo7nO1Wi0sWrRICAwMFOzs7ISAgADh/fff12175MgRITQ0VFAoFEJkZKSwZcsWAYCQnJwsCIIgrF27VnB1da3WrlOnTgnh4eGCXC4XOnXqJGzZsqXaeWVlZQlTpkwRPD09BYVCIYSEhAg//fST3n5++eUXAYDw3Xff1fm7qO3PS0O+vyWCUM8BH0hPfn4+XF1dkZeXBxcXF0s3h4ioRSstLUVycjKCgoKgUCgs3RyygA0bNmDmzJm4efMmZLLa77bU9uelId/ffLqNiIiImq3i4mIkJycjJiYG//73v+sMSKbEmiQiIqJmbsOGDXBycjL40o511FItWbIE9957L7y9vTF37lyzHpu324zE221EROZzt99uKygoQHp6usHP7OzsEBgYaOYWNW+83UZERHSXcHZ2bvIpOKg63m4jIiKrwZsfVB+m+nPCkERERM2eVCoFAKNGo6a7T3FxMQDxVmRj8HYbERE1e7a2tnBwcMCtW7dgZ2enmyaD6HaCIKC4uBgZGRlwc3PThWtjMSQREVGzJ5FI4Ovri+TkZFy7ds3SzaFmzs3NDT4+Po3eD0MSERFZBZlMhk6dOvGWG9XKzs6u0T1IWgxJRERkNWxsbO7KIQDIMnhTl4iIiMgAhiQiIiIiAxiSiIiIiAxgTZKRtANV5efnW7glREREVF/a7+36DDjJkGSkgoICAIC/v7+FW0JEREQNVVBQAFdX11rX4QS3RtJoNLh58yacnZ0hkUhMuu/8/Hz4+/sjNTW1xU+ey3Ntue6m8+W5tlx30/neLecqCAIKCgrg5+dX56Ck7Ekyko2NDdq2bdukx3BxcWnRf1Bvx3Ntue6m8+W5tlx30/neDedaVw+SFgu3iYiIiAxgSCIiIiIygCGpGZLL5XjnnXcgl8st3ZQmx3Ntue6m8+W5tlx30/neTedaXyzcJiIiIjKAPUlEREREBjAkERERERnAkERERERkAEMSERERkQEMSRayYsUKBAUFQaFQICwsDIcPH651/UOHDiEsLAwKhQLt27fHF198YaaWGi8mJgb33XcfnJ2d0bp1a4waNQoXL16sdZuDBw9CIpFUe/39999marVxFixYUK3NPj4+tW5jjddUq127dgav04svvmhwfWu6rr/99htGjhwJPz8/SCQS7NixQ+9zQRCwYMEC+Pn5wd7eHg888AAuXLhQ5363bt2Kbt26QS6Xo1u3bti+fXsTnUH91Xau5eXlePPNNxEaGgpHR0f4+fnh6aefxs2bN2vd57p16wxe69LS0iY+m7rVdW0nT55crd19+vSpc7/Wdm0BGLxGEokEH374YY37bM7XtqkwJFnA5s2bMWvWLMybNw+nT59GZGQkhg8fjpSUFIPrJycnY8SIEYiMjMTp06fxn//8BzNmzMDWrVvN3PKGOXToEF588UUcO3YMcXFxqKioQFRUFIqKiurc9uLFi1AqlbpXp06dzNDixgkODtZr87lz52pc11qvqdaJEyf0zjUuLg4AMHbs2Fq3s4brWlRUhB49emD58uUGP1+yZAk+/vhjLF++HCdOnICPjw8efPBB3XyOhvzxxx8YP348oqOjcebMGURHR2PcuHE4fvx4U51GvdR2rsXFxTh16hTmz5+PU6dOYdu2bbh06RIeeeSROvfr4uKid52VSiUUCkVTnEKD1HVtAWDYsGF67d69e3et+7TGawug2vVZs2YNJBIJxowZU+t+m+u1bTICmd39998vTJ8+XW9Zly5dhDlz5hhc/4033hC6dOmit+zf//630KdPnyZrY1PIyMgQAAiHDh2qcZ0DBw4IAIScnBzzNcwE3nnnHaFHjx71Xr+lXFOtmTNnCh06dBA0Go3Bz631ugIQtm/frnuv0WgEHx8fYfHixbplpaWlgqurq/DFF1/UuJ9x48YJw4YN01s2dOhQYcKECSZvs7HuPFdD/vzzTwGAcO3atRrXWbt2reDq6mraxjUBQ+c7adIk4dFHH23QflrKtX300UeFQYMG1bqOtVxbU2JPkpmVlZXh5MmTiIqK0lseFRWFo0ePGtzmjz/+qLb+0KFD8ddff6G8vLzJ2mpqeXl5AAAPD4861+3Zsyd8fX0xePBgHDhwoKmbZhJJSUnw8/NDUFAQJkyYgCtXrtS4bku5poD4Z/qbb77BM888U+dkz9Z4XW+XnJyMtLQ0vWsnl8sxcODAGv/+AjVf79q2aY7y8vIgkUjg5uZW63qFhYUIDAxE27Zt8fDDD+P06dPmaaAJHDx4EK1bt0bnzp3x7LPPIiMjo9b1W8K1TU9Px65duzB16tQ617Xma2sMhiQzy8zMhFqthre3t95yb29vpKWlGdwmLS3N4PoVFRXIzMxssraakiAImD17Nvr374+QkJAa1/P19cWqVauwdetWbNu2Dffccw8GDx6M3377zYytbbjevXtj/fr12LdvH1avXo20tDREREQgKyvL4Pot4Zpq7dixA7m5uZg8eXKN61jrdb2T9u9oQ/7+ardr6DbNTWlpKebMmYMnnnii1slPu3TpgnXr1mHnzp3YuHEjFAoF+vXrh6SkJDO21jjDhw/Hhg0b8Ouvv2Lp0qU4ceIEBg0aBJVKVeM2LeHafvXVV3B2dsbo0aNrXc+ar62xbC3dgLvVnf/iFgSh1n+FG1rf0PLm6qWXXsLZs2dx5MiRWte75557cM899+je9+3bF6mpqfjoo48wYMCApm6m0YYPH677OTQ0FH379kWHDh3w1VdfYfbs2Qa3sfZrqhUbG4vhw4fDz8+vxnWs9brWpKF/f43dprkoLy/HhAkToNFosGLFilrX7dOnj16xc79+/dCrVy98/vnn+Oyzz5q6qY0yfvx43c8hISEIDw9HYGAgdu3aVWuAsOZrCwBr1qzBk08+WWdtkTVfW2OxJ8nMWrVqBalUWu1fGRkZGdX+NaLl4+NjcH1bW1t4eno2WVtN5eWXX8bOnTtx4MABtG3btsHb9+nTx+r+peLo6IjQ0NAa223t11Tr2rVr2L9/P6ZNm9bgba3xumqfWGzI31/tdg3dprkoLy/HuHHjkJycjLi4uFp7kQyxsbHBfffdZ3XXGhB7QAMDA2ttuzVfWwA4fPgwLl68aNTfYWu+tvXFkGRmMpkMYWFhuqeBtOLi4hAREWFwm759+1Zb/+eff0Z4eDjs7OyarK2NJQgCXnrpJWzbtg2//vorgoKCjNrP6dOn4evra+LWNS2VSoXExMQa222t1/ROa9euRevWrfHQQw81eFtrvK5BQUHw8fHRu3ZlZWU4dOhQjX9/gZqvd23bNAfagJSUlIT9+/cbFeAFQUB8fLzVXWsAyMrKQmpqaq1tt9ZrqxUbG4uwsDD06NGjwdta87WtN0tVjN/NNm3aJNjZ2QmxsbFCQkKCMGvWLMHR0VG4evWqIAiCMGfOHCE6Olq3/pUrVwQHBwfhlVdeERISEoTY2FjBzs5O+P777y11CvXy/PPPC66ursLBgwcFpVKpexUXF+vWufNcP/nkE2H79u3CpUuXhPPnzwtz5swRAAhbt261xCnU26uvviocPHhQuHLlinDs2DHh4YcfFpydnVvcNb2dWq0WAgIChDfffLPaZ9Z8XQsKCoTTp08Lp0+fFgAIH3/8sXD69GndE12LFy8WXF1dhW3btgnnzp0TJk6cKPj6+gr5+fm6fURHR+s9rfr7778LUqlUWLx4sZCYmCgsXrxYsLW1FY4dO2b287tdbedaXl4uPPLII0Lbtm2F+Ph4vb/DKpVKt487z3XBggXC3r17hcuXLwunT58WpkyZItja2grHjx+3xCnqqe18CwoKhFdffVU4evSokJycLBw4cEDo27ev0KZNmxZ3bbXy8vIEBwcHYeXKlQb3YU3XtqkwJFnI//73PyEwMFCQyWRCr1699B6LnzRpkjBw4EC99Q8ePCj07NlTkMlkQrt27Wr8Q92cADD4Wrt2rW6dO8/1gw8+EDp06CAoFArB3d1d6N+/v7Br1y7zN76Bxo8fL/j6+gp2dnaCn5+fMHr0aOHChQu6z1vKNb3dvn37BADCxYsXq31mzddVO1zBna9JkyYJgiAOA/DOO+8IPj4+glwuFwYMGCCcO3dObx8DBw7Ura+1ZcsW4Z577hHs7OyELl26NIuAWNu5Jicn1/h3+MCBA7p93Hmus2bNEgICAgSZTCZ4eXkJUVFRwtGjR81/cgbUdr7FxcVCVFSU4OXlJdjZ2QkBAQHCpEmThJSUFL19tIRrq/Xll18K9vb2Qm5ursF9WNO1bSoSQaisFiUiIiIiHdYkERERERnAkERERERkAEMSERERkQEMSUREREQGMCQRERERGcCQRERERGQAQxIRERGRAQxJRERERAYwJBERNYJEIsGOHTss3QwiagIMSURktSZPngyJRFLtNWzYMEs3jYhaAFtLN4CIqDGGDRuGtWvX6i2Ty+UWag0RtSTsSSIiqyaXy+Hj46P3cnd3ByDeClu5ciWGDx8Oe3t7BAUFYcuWLXrbnzt3DoMGDYK9vT08PT3x3HPPobCwUG+dNWvWIDg4GHK5HL6+vnjppZf0Ps/MzMRjjz0GBwcHdOrUCTt37tR9lpOTgyeffBJeXl6wt7dHp06dqoU6ImqeGJKIqEWbP38+xowZgzNnzuCpp57CxIkTkZiYCAAoLi7GsGHD4O7ujhMnTmDLli3Yv3+/XghauXIlXnzxRTz33HM4d+4cdu7ciY4dO+od491338W4ceNw9uxZjBgxAk8++SSys7N1x09ISMCePXuQmJiIlStXolWrVub7BRCR8QQiIis1adIkQSqVCo6OjnqvhQsXCoIgCACE6dOn623Tu3dv4fnnnxcEQRBWrVoluLu7C4WFhbrPd+3aJdjY2AhpaWmCIAiCn5+fMG/evBrbAEB46623dO8LCwsFiUQi7NmzRxAEQRg5cqQwZcoU05wwEZkVa5KIyKr961//wsqVK/WWeXh46H7u27ev3md9+/ZFfHw8ACAxMRE9evSAo6Oj7vN+/fpBo9Hg4sWLkEgkuHnzJgYPHlxrG7p376772dHREc7OzsjIyAAAPP/88xgzZgxOnTqFqKgojBo1ChEREUadKxGZF0MSEVk1R0fHare/6iKRSAAAgiDofja0jr29fb32Z2dnV21bjUYDABg+fDiuXbuGXbt2Yf/+/Rg8eDBefPFFfPTRRw1qMxGZH2uSiKhFO3bsWLX3Xbp0AQB069YN8fHxKCoq0n3++++/w8bGBp07d4azszPatWuHX375pVFt8PLywuTJk/HNN9/g008/xapVqxq1PyIyD/YkEZFVU6lUSEtL01tma2urK47esmULwsPD0b9/f2zYsAF//vknYmNjAQBPPvkk3nnnHUyaNAkLFizArVu38PLLLyM6Ohre3t4AgAULFmD69Olo3bo1hg8fjoKCAvz+++94+eWX69W+t99+G2FhYQgODoZKpcJPP/2Erl27mvA3QERNhSGJiKza3r174evrq7fsnnvuwd9//w1AfPJs06ZNeOGFF+Dj44MNGzagW7duAAAHBwfs27cPM2fOxH333QcHBweMGTMGH3/8sW5fkyZNQmlpKT755BO89tpraNWqFR5//PF6t08mk2Hu3Lm4evUq7O3tERkZiU2bNpngzImoqUkEQRAs3QgioqYgkUiwfft2jBo1ytJNISIrxJokIiIiIgMYkoiIiIgMYE0SEbVYrCYgosZgTxIRERGRAQxJRERERAYwJBEREREZwJBEREREZABDEhEREZEBDElEREREBjAkERERERnAkERERERkwP8Do2rCczulYmcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_history(history, key):\n",
    "  plt.plot(history.history[key])\n",
    "  plt.plot(history.history['val_'+key])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(key)\n",
    "  plt.legend([key, 'val_'+key])\n",
    "  plt.show()\n",
    "# Plot the history\n",
    "plot_history(history, 'loss')\n",
    "plot_history(history, 'accuracy')\n",
    "# plot_history(history, 'precision')\n",
    "# plot_history(history, 'recall')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8520 - loss: 0.3660\n",
      "Accuracy: 86.65\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Precision: 75.70\n",
      "Recall: 51.92\n",
      "F1-score: 61.60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "# _, accuracy = model.evaluate(X_test, y_test)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "# print(metrics)\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred >= 0.9).astype(int)  # Convert probabilities to binary predictions   \n",
    "\n",
    "\n",
    "# Calculate additional metrics\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test,  y_pred_binary)\n",
    "\n",
    "print('Precision: %.2f' % (precision*100))\n",
    "print('Recall: %.2f' % (recall*100))\n",
    "print('F1-score: %.2f' % (f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot(fpr,tpr,label=\"auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7051/3811204352.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  crime_hotspots.loc[:,'predicted'] = y_pred_binary\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "crime_hotspots = test_hotspots_crime_counts_df[test_hotspots_crime_counts_df.time_bin.dt.date >= datetime.date(2017, 3, 1) ]\n",
    "\n",
    "crime_hotspots.loc[:,'predicted'] = y_pred_binary\n",
    "# crime_hotspots.to_csv('forecasted_result.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_size = 600\n",
    "grid = gpd.read_file(os.path.join(current_dir, 'Data', 'grids', str(cell_size),  'crime-forecast-grid.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time_step_starting_dates = test_time_bins[-7:]\n",
    "test_time_step_starting_dates\n",
    "crime_hotspots_1st_week = crime_hotspots[crime_hotspots.time_bin.dt.date == test_time_step_starting_dates[0].date() ]\n",
    "\n",
    "predicted_grid_ids = np.array(crime_hotspots_1st_week[crime_hotspots_1st_week['predicted'] == 1].unique_id)\n",
    "hotspot_grid_ids = np.array(crime_hotspots_1st_week[crime_hotspots_1st_week['hotspot'] == 1].unique_id)\n",
    "\n",
    "\n",
    "total_crimes_in_predicted_hotspots = crime_hotspots_1st_week[crime_hotspots_1st_week['predicted'] == 1].crime_count.sum()\n",
    "total_crimes = test_crime_counts_df[test_crime_counts_df.time_bin.dt.date == test_time_step_starting_dates[0].date()].crime_count.sum()\n",
    "\n",
    "predicted_hotspots_area = grid[grid.unique_id.isin(predicted_grid_ids)].area.sum()\n",
    "total_area = grid.area.sum()\n",
    "# # # x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAI = 57.8419450698782\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(total_crimes_in_predicted_hotspots)\n",
    "# print(total_crimes)\n",
    "# print(predicted_hotspots_area)\n",
    "# print(total_area)\n",
    "\n",
    "\n",
    "pai = (total_crimes_in_predicted_hotspots / total_crimes) / (predicted_hotspots_area / total_area)\n",
    "print(f\"PAI = {pai}\")\n",
    "# pai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEI: 0.9328859060402684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grid[grid.unique_id.isin(hotspot_grid_ids)]\n",
    "desc_sorted = -np.sort(-np.array(crime_hotspots_1st_week.crime_count))\n",
    "\n",
    "number_of_cells = int(predicted_hotspots_area/ (cell_size**2)) # Rough estimation that each cell is of size cell_size_sq\n",
    "maximum_obtainable_crimes_for_the_forecasted_area = desc_sorted[:number_of_cells].sum()\n",
    "\n",
    "pei = total_crimes_in_predicted_hotspots / (maximum_obtainable_crimes_for_the_forecasted_area)\n",
    "print(f\"PEI: {pei}\")\n",
    "\n",
    "# grid['pre']\n",
    "    \n",
    "# # y_test\n",
    "# test_crime_counts_df.crime_count.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 25, 14)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_grid_ids), len(hotspot_grid_ids), len(np.intersect1d(predicted_grid_ids, hotspot_grid_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>hotspot</th>\n",
       "      <th>x_index</th>\n",
       "      <th>y_index</th>\n",
       "      <th>area</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>126069.479649</td>\n",
       "      <td>POLYGON ((7604013.056 710715.558, 7604604.588 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>347437.898186</td>\n",
       "      <td>POLYGON ((7604037.994 711315.558, 7604604.588 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>332474.858733</td>\n",
       "      <td>POLYGON ((7604062.933 711915.558, 7604604.588 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>317511.819280</td>\n",
       "      <td>POLYGON ((7604087.871 712515.558, 7604604.588 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>302548.779827</td>\n",
       "      <td>POLYGON ((7604112.809 713115.558, 7604604.588 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11980</th>\n",
       "      <td>11981</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>81</td>\n",
       "      <td>259345.783629</td>\n",
       "      <td>POLYGON ((7700604.588 700123.915, 7700604.588 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11981</th>\n",
       "      <td>11982</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>82</td>\n",
       "      <td>2816.972293</td>\n",
       "      <td>POLYGON ((7700090.578 700515.558, 7700004.588 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11982</th>\n",
       "      <td>11983</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>80</td>\n",
       "      <td>173713.379556</td>\n",
       "      <td>POLYGON ((7701204.588 699666.753, 7701204.588 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11983</th>\n",
       "      <td>11984</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>81</td>\n",
       "      <td>28488.405276</td>\n",
       "      <td>POLYGON ((7700878.046 699915.558, 7700604.588 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11984</th>\n",
       "      <td>11985</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>80</td>\n",
       "      <td>16425.120496</td>\n",
       "      <td>POLYGON ((7701204.588 699521.755, 7701204.588 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11985 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_id  hotspot  x_index  y_index           area  \\\n",
       "0              1        0        0       98  126069.479649   \n",
       "1              2        0        0       99  347437.898186   \n",
       "2              3        0        0      100  332474.858733   \n",
       "3              4        0        0      101  317511.819280   \n",
       "4              5        0        0      102  302548.779827   \n",
       "...          ...      ...      ...      ...            ...   \n",
       "11980      11981        0      160       81  259345.783629   \n",
       "11981      11982        0      160       82    2816.972293   \n",
       "11982      11983        0      161       80  173713.379556   \n",
       "11983      11984        0      161       81   28488.405276   \n",
       "11984      11985        0      162       80   16425.120496   \n",
       "\n",
       "                                                geometry  \n",
       "0      POLYGON ((7604013.056 710715.558, 7604604.588 ...  \n",
       "1      POLYGON ((7604037.994 711315.558, 7604604.588 ...  \n",
       "2      POLYGON ((7604062.933 711915.558, 7604604.588 ...  \n",
       "3      POLYGON ((7604087.871 712515.558, 7604604.588 ...  \n",
       "4      POLYGON ((7604112.809 713115.558, 7604604.588 ...  \n",
       "...                                                  ...  \n",
       "11980  POLYGON ((7700604.588 700123.915, 7700604.588 ...  \n",
       "11981  POLYGON ((7700090.578 700515.558, 7700004.588 ...  \n",
       "11982  POLYGON ((7701204.588 699666.753, 7701204.588 ...  \n",
       "11983  POLYGON ((7700878.046 699915.558, 7700604.588 ...  \n",
       "11984  POLYGON ((7701204.588 699521.755, 7701204.588 ...  \n",
       "\n",
       "[11985 rows x 6 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.loc[grid.unique_id.isin(predicted_grid_ids), 'hotspot'] = 1\n",
    "grid.loc[grid.unique_id.isin(hotspot_grid_ids), 'hotspot'] = 2\n",
    "grid.loc[grid.unique_id.isin(np.intersect1d(predicted_grid_ids, hotspot_grid_ids)), 'hotspot'] = 3\n",
    "grid.to_file(f\"visualizations/{cell_size}/crime-forecast-grid.shp\")\n",
    "\n",
    "grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD extra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7290 - loss: 0.5584\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7621 - loss: 0.5085\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7804 - loss: 0.4726\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7678 - loss: 0.4830\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7559 - loss: 0.5091\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7789 - loss: 0.4784\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7880 - loss: 0.4844\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7998 - loss: 0.4536\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7719 - loss: 0.4841\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7753 - loss: 0.4778\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7778 - loss: 0.4752\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7695 - loss: 0.4876\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7917 - loss: 0.4576\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7775 - loss: 0.4738\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7694 - loss: 0.4882\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7889 - loss: 0.4803\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7900 - loss: 0.4656\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7758 - loss: 0.4568\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7750 - loss: 0.4754\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7653 - loss: 0.4690\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7489 - loss: 0.5371\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7708 - loss: 0.4948\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7897 - loss: 0.4699\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7820 - loss: 0.4930\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7896 - loss: 0.4689\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7774 - loss: 0.4898\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8048 - loss: 0.4491\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7826 - loss: 0.4821\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7910 - loss: 0.4627\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7967 - loss: 0.4679\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7977 - loss: 0.4525\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8035 - loss: 0.4632\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7878 - loss: 0.4622\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7823 - loss: 0.4792\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7896 - loss: 0.4837\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7843 - loss: 0.4736\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7849 - loss: 0.4651\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7871 - loss: 0.4568\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7979 - loss: 0.4551\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7888 - loss: 0.4797\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7315 - loss: 0.5298\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7964 - loss: 0.4615\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7940 - loss: 0.4578\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7712 - loss: 0.4890\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7753 - loss: 0.4732\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7999 - loss: 0.4490\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7998 - loss: 0.4475\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7899 - loss: 0.4392\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8146 - loss: 0.4348\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7894 - loss: 0.4452\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8005 - loss: 0.4563\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7883 - loss: 0.4608\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7929 - loss: 0.4648\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7957 - loss: 0.4411\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8091 - loss: 0.4421\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7872 - loss: 0.4549\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7969 - loss: 0.4532\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8023 - loss: 0.4421\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8047 - loss: 0.4357\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7884 - loss: 0.4577\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.7422 - loss: 0.5464\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7772 - loss: 0.4938\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7594 - loss: 0.5081\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7722 - loss: 0.4851\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7665 - loss: 0.4902\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7709 - loss: 0.4824\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7519 - loss: 0.5089\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7722 - loss: 0.4707\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7641 - loss: 0.4807\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7811 - loss: 0.4680\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7869 - loss: 0.4724\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7814 - loss: 0.4755\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7835 - loss: 0.4684\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7733 - loss: 0.4738\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7633 - loss: 0.4887\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7841 - loss: 0.4689\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7672 - loss: 0.4868\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7747 - loss: 0.4765\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7794 - loss: 0.4660\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7850 - loss: 0.4516\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.7399 - loss: 0.5391\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8020 - loss: 0.4711\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7740 - loss: 0.4806\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7807 - loss: 0.4843\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7827 - loss: 0.4772\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7644 - loss: 0.4873\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7893 - loss: 0.4758\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7721 - loss: 0.4940\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7983 - loss: 0.4645\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7952 - loss: 0.4627\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7850 - loss: 0.4748\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7918 - loss: 0.4520\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7956 - loss: 0.4735\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7955 - loss: 0.4541\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.7888 - loss: 0.4675\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7983 - loss: 0.4573\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8005 - loss: 0.4515\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7856 - loss: 0.4695\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7982 - loss: 0.4545\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7945 - loss: 0.4513\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.7652 - loss: 0.5256\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7844 - loss: 0.4822\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7903 - loss: 0.4649\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7974 - loss: 0.4566\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7975 - loss: 0.4502\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7994 - loss: 0.4547\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7784 - loss: 0.4640\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7837 - loss: 0.4691\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7837 - loss: 0.4635\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7988 - loss: 0.4464\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8090 - loss: 0.4403\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7893 - loss: 0.4672\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7922 - loss: 0.4623\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7942 - loss: 0.4564\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8072 - loss: 0.4425\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8150 - loss: 0.4328\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7764 - loss: 0.4638\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8085 - loss: 0.4355\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8016 - loss: 0.4515\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8015 - loss: 0.4380\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.7194 - loss: 0.5630\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7648 - loss: 0.4954\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7727 - loss: 0.4979\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.7781 - loss: 0.4800\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7788 - loss: 0.4892\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7710 - loss: 0.4950\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7807 - loss: 0.4817\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7637 - loss: 0.4989\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7825 - loss: 0.4698\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7827 - loss: 0.4742\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7747 - loss: 0.4705\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7923 - loss: 0.4461\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7809 - loss: 0.4773\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7912 - loss: 0.4636\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7846 - loss: 0.4535\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7650 - loss: 0.4877\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7925 - loss: 0.4603\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7744 - loss: 0.4846\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7706 - loss: 0.4926\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7710 - loss: 0.4718\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.7179 - loss: 0.5793\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7915 - loss: 0.4928\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7800 - loss: 0.4823\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7850 - loss: 0.4736\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8004 - loss: 0.4555\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7907 - loss: 0.4711\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7808 - loss: 0.4698\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7977 - loss: 0.4644\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7776 - loss: 0.4709\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7953 - loss: 0.4600\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7944 - loss: 0.4655\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7869 - loss: 0.4632\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7912 - loss: 0.4542\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7968 - loss: 0.4565\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7834 - loss: 0.4651\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7938 - loss: 0.4598\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7966 - loss: 0.4544\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7846 - loss: 0.4703\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7931 - loss: 0.4500\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7888 - loss: 0.4781\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.7372 - loss: 0.5780\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7979 - loss: 0.4584\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7904 - loss: 0.4647\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7826 - loss: 0.4707\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8035 - loss: 0.4620\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8006 - loss: 0.4568\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8073 - loss: 0.4401\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7958 - loss: 0.4468\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7816 - loss: 0.4657\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7839 - loss: 0.4653\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7850 - loss: 0.4622\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7939 - loss: 0.4616\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7995 - loss: 0.4398\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7944 - loss: 0.4553\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7940 - loss: 0.4519\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7950 - loss: 0.4542\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7876 - loss: 0.4481\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8021 - loss: 0.4273\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7993 - loss: 0.4487\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.7866 - loss: 0.4577\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7429 - loss: 0.5703\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7744 - loss: 0.4922\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7777 - loss: 0.4859\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7676 - loss: 0.4903\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7742 - loss: 0.4830\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7828 - loss: 0.4746\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7712 - loss: 0.4911\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7749 - loss: 0.4853\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7671 - loss: 0.4841\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7794 - loss: 0.4681\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7801 - loss: 0.4677\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7658 - loss: 0.4809\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7721 - loss: 0.4813\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7736 - loss: 0.4806\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7842 - loss: 0.4616\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7637 - loss: 0.4935\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7697 - loss: 0.4826\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7873 - loss: 0.4636\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7926 - loss: 0.4602\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7833 - loss: 0.4642\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.6760 - loss: 0.5871\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7911 - loss: 0.4715\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7958 - loss: 0.4675\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7948 - loss: 0.4706\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7893 - loss: 0.4813\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7857 - loss: 0.4777\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7726 - loss: 0.4849\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8039 - loss: 0.4424\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7901 - loss: 0.4703\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7944 - loss: 0.4562\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7846 - loss: 0.4754\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7866 - loss: 0.4779\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7948 - loss: 0.4727\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7854 - loss: 0.4746\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7877 - loss: 0.4660\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7948 - loss: 0.4605\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7830 - loss: 0.4702\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7749 - loss: 0.4863\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7926 - loss: 0.4655\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7967 - loss: 0.4598\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7279 - loss: 0.5579\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7807 - loss: 0.4708\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8006 - loss: 0.4510\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7948 - loss: 0.4650\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7932 - loss: 0.4503\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7990 - loss: 0.4449\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7883 - loss: 0.4534\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7859 - loss: 0.4786\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8008 - loss: 0.4460\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8073 - loss: 0.4428\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7949 - loss: 0.4528\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7916 - loss: 0.4560\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8052 - loss: 0.4535\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7993 - loss: 0.4382\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7999 - loss: 0.4415\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7892 - loss: 0.4598\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8168 - loss: 0.4125\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7996 - loss: 0.4523\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7977 - loss: 0.4515\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8095 - loss: 0.4376\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7127 - loss: 0.5576\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7673 - loss: 0.5001\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7811 - loss: 0.4799\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7758 - loss: 0.4848\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7550 - loss: 0.5056\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7862 - loss: 0.4727\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7741 - loss: 0.4790\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7670 - loss: 0.4928\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7767 - loss: 0.4808\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7804 - loss: 0.4826\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7840 - loss: 0.4783\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7805 - loss: 0.4734\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7939 - loss: 0.4415\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7793 - loss: 0.4696\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7728 - loss: 0.4841\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7793 - loss: 0.4731\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7677 - loss: 0.4769\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7650 - loss: 0.4825\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7574 - loss: 0.4936\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7799 - loss: 0.4797\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.7258 - loss: 0.5474\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7874 - loss: 0.4664\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7623 - loss: 0.4979\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7872 - loss: 0.4737\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7939 - loss: 0.4711\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7939 - loss: 0.4781\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7919 - loss: 0.4610\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7865 - loss: 0.4838\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8050 - loss: 0.4540\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7986 - loss: 0.4565\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7989 - loss: 0.4523\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8041 - loss: 0.4658\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7871 - loss: 0.4794\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7943 - loss: 0.4609\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8064 - loss: 0.4472\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8034 - loss: 0.4589\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7949 - loss: 0.4568\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7983 - loss: 0.4576\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7952 - loss: 0.4601\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8104 - loss: 0.4470\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7080 - loss: 0.5380\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7942 - loss: 0.4658\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7720 - loss: 0.4750\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7870 - loss: 0.4593\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7977 - loss: 0.4511\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7778 - loss: 0.4674\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7947 - loss: 0.4516\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7918 - loss: 0.4531\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7970 - loss: 0.4468\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8047 - loss: 0.4393\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7901 - loss: 0.4594\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7928 - loss: 0.4545\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7979 - loss: 0.4356\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7887 - loss: 0.4572\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8077 - loss: 0.4372\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7981 - loss: 0.4496\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8048 - loss: 0.4431\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7982 - loss: 0.4472\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7780 - loss: 0.4807\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7977 - loss: 0.4435\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.7011 - loss: 0.5585\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7651 - loss: 0.4916\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7674 - loss: 0.4841\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7751 - loss: 0.4876\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7771 - loss: 0.4874\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7778 - loss: 0.4753\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7808 - loss: 0.4768\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7810 - loss: 0.4667\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7751 - loss: 0.4854\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7726 - loss: 0.4856\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7733 - loss: 0.4827\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7641 - loss: 0.4860\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7738 - loss: 0.4849\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7837 - loss: 0.4676\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7869 - loss: 0.4669\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7713 - loss: 0.4834\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7641 - loss: 0.4812\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7912 - loss: 0.4649\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7924 - loss: 0.4593\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7534 - loss: 0.4869\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.7319 - loss: 0.5305\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7701 - loss: 0.4911\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7784 - loss: 0.4848\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8064 - loss: 0.4437\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7989 - loss: 0.4670\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8071 - loss: 0.4480\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7903 - loss: 0.4697\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7940 - loss: 0.4727\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7934 - loss: 0.4647\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7882 - loss: 0.4697\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7935 - loss: 0.4609\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8001 - loss: 0.4632\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7956 - loss: 0.4705\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7727 - loss: 0.4858\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8029 - loss: 0.4622\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7950 - loss: 0.4657\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8070 - loss: 0.4566\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7925 - loss: 0.4652\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7974 - loss: 0.4598\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7902 - loss: 0.4725\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.7010 - loss: 0.5526\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7877 - loss: 0.4663\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7927 - loss: 0.4511\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7760 - loss: 0.4848\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7858 - loss: 0.4712\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7981 - loss: 0.4434\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7859 - loss: 0.4515\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7809 - loss: 0.4754\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7981 - loss: 0.4476\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7983 - loss: 0.4616\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7999 - loss: 0.4470\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8110 - loss: 0.4380\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7905 - loss: 0.4522\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7885 - loss: 0.4602\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7985 - loss: 0.4424\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7973 - loss: 0.4503\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8122 - loss: 0.4444\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7990 - loss: 0.4509\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8029 - loss: 0.4463\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8051 - loss: 0.4388\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5116 - loss: 0.6787\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7604 - loss: 0.5869\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7911 - loss: 0.4859\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7603 - loss: 0.5086\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7737 - loss: 0.4914\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7686 - loss: 0.4898\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7605 - loss: 0.5018\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7707 - loss: 0.4838\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7656 - loss: 0.4867\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7636 - loss: 0.4968\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7731 - loss: 0.4853\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7732 - loss: 0.4783\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7729 - loss: 0.4752\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7840 - loss: 0.4774\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7814 - loss: 0.4703\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7667 - loss: 0.4959\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7736 - loss: 0.4854\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7649 - loss: 0.4966\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7676 - loss: 0.4875\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7614 - loss: 0.4884\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.4060 - loss: 0.7413\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7648 - loss: 0.6607\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7611 - loss: 0.5430\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7800 - loss: 0.4912\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7890 - loss: 0.4745\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7749 - loss: 0.4899\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7616 - loss: 0.4957\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7863 - loss: 0.4677\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7905 - loss: 0.4589\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7757 - loss: 0.4762\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7812 - loss: 0.4786\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7800 - loss: 0.4641\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7963 - loss: 0.4575\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7787 - loss: 0.4761\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7912 - loss: 0.4604\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7689 - loss: 0.4908\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7908 - loss: 0.4631\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7757 - loss: 0.4903\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7755 - loss: 0.4745\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7790 - loss: 0.4882\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.5306 - loss: 0.6720\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7842 - loss: 0.5845\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7791 - loss: 0.4950\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7711 - loss: 0.4860\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7789 - loss: 0.4728\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7766 - loss: 0.4793\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7722 - loss: 0.4757\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8054 - loss: 0.4449\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7886 - loss: 0.4620\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7808 - loss: 0.4671\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7725 - loss: 0.4752\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7967 - loss: 0.4584\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7894 - loss: 0.4574\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8050 - loss: 0.4375\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7899 - loss: 0.4605\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7854 - loss: 0.4563\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7902 - loss: 0.4551\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7825 - loss: 0.4652\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8066 - loss: 0.4388\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7962 - loss: 0.4548\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.6656 - loss: 0.6522\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7638 - loss: 0.5043\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7753 - loss: 0.4823\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7620 - loss: 0.5044\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7774 - loss: 0.4882\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7861 - loss: 0.4677\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7710 - loss: 0.4840\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7901 - loss: 0.4784\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7713 - loss: 0.4841\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7815 - loss: 0.4704\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7760 - loss: 0.4719\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7773 - loss: 0.4746\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7622 - loss: 0.4893\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7756 - loss: 0.4805\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7676 - loss: 0.4874\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7609 - loss: 0.4991\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7702 - loss: 0.4804\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7770 - loss: 0.4817\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7737 - loss: 0.4774\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7748 - loss: 0.4735\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.5669 - loss: 0.6654\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7675 - loss: 0.5027\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7748 - loss: 0.4850\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7843 - loss: 0.4835\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7711 - loss: 0.4884\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7939 - loss: 0.4750\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7883 - loss: 0.4625\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7783 - loss: 0.4907\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7836 - loss: 0.4714\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7789 - loss: 0.4812\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7703 - loss: 0.4932\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7816 - loss: 0.4855\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7855 - loss: 0.4668\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8078 - loss: 0.4413\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7952 - loss: 0.4685\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7855 - loss: 0.4698\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7962 - loss: 0.4575\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7862 - loss: 0.4816\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7777 - loss: 0.4738\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7925 - loss: 0.4623\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.6240 - loss: 0.6584\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7828 - loss: 0.4815\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7868 - loss: 0.4664\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7808 - loss: 0.4741\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7842 - loss: 0.4782\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7757 - loss: 0.4683\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7883 - loss: 0.4642\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7837 - loss: 0.4705\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8001 - loss: 0.4517\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7926 - loss: 0.4625\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7819 - loss: 0.4611\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7909 - loss: 0.4511\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7910 - loss: 0.4554\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7847 - loss: 0.4764\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7955 - loss: 0.4561\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7909 - loss: 0.4532\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7968 - loss: 0.4395\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7808 - loss: 0.4595\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7902 - loss: 0.4562\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8106 - loss: 0.4259\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.6697 - loss: 0.6085\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7686 - loss: 0.4973\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7684 - loss: 0.4921\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7584 - loss: 0.4938\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7734 - loss: 0.4759\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7659 - loss: 0.4914\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7677 - loss: 0.4897\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7642 - loss: 0.4998\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7783 - loss: 0.4739\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7705 - loss: 0.4829\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7857 - loss: 0.4662\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7664 - loss: 0.4906\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7670 - loss: 0.4828\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7737 - loss: 0.4762\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7637 - loss: 0.4945\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7655 - loss: 0.4843\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7721 - loss: 0.4797\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7755 - loss: 0.4663\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7796 - loss: 0.4816\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7717 - loss: 0.4864\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.5941 - loss: 0.6272\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7815 - loss: 0.4775\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7825 - loss: 0.4757\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7758 - loss: 0.4786\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7740 - loss: 0.4879\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7756 - loss: 0.4876\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7734 - loss: 0.4886\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7802 - loss: 0.4766\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7920 - loss: 0.4598\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8010 - loss: 0.4575\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7809 - loss: 0.4665\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7980 - loss: 0.4566\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7870 - loss: 0.4640\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8089 - loss: 0.4578\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7747 - loss: 0.4842\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7762 - loss: 0.4834\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7874 - loss: 0.4715\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8101 - loss: 0.4529\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8054 - loss: 0.4452\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8045 - loss: 0.4574\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.6401 - loss: 0.6096\n",
      "Epoch 2/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7983 - loss: 0.4517\n",
      "Epoch 3/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7745 - loss: 0.4803\n",
      "Epoch 4/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7933 - loss: 0.4607\n",
      "Epoch 5/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7884 - loss: 0.4643\n",
      "Epoch 6/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7924 - loss: 0.4527\n",
      "Epoch 7/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7985 - loss: 0.4537\n",
      "Epoch 8/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7852 - loss: 0.4587\n",
      "Epoch 9/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7877 - loss: 0.4490\n",
      "Epoch 10/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7821 - loss: 0.4655\n",
      "Epoch 11/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7904 - loss: 0.4585\n",
      "Epoch 12/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7904 - loss: 0.4631\n",
      "Epoch 13/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8017 - loss: 0.4489\n",
      "Epoch 14/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7995 - loss: 0.4364\n",
      "Epoch 15/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8011 - loss: 0.4459\n",
      "Epoch 16/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8027 - loss: 0.4377\n",
      "Epoch 17/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7886 - loss: 0.4478\n",
      "Epoch 18/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8006 - loss: 0.4449\n",
      "Epoch 19/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8023 - loss: 0.4469\n",
      "Epoch 20/20\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7937 - loss: 0.4600\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.6885 - loss: 0.5751\n",
      "Epoch 2/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7646 - loss: 0.5055\n",
      "Epoch 3/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7710 - loss: 0.4900\n",
      "Epoch 4/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7736 - loss: 0.4806\n",
      "Epoch 5/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7785 - loss: 0.4814\n",
      "Epoch 6/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7663 - loss: 0.4822\n",
      "Epoch 7/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7780 - loss: 0.4771\n",
      "Epoch 8/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7737 - loss: 0.4916\n",
      "Epoch 9/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7622 - loss: 0.4824\n",
      "Epoch 10/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7618 - loss: 0.4881\n",
      "Epoch 11/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7776 - loss: 0.4759\n",
      "Epoch 12/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7786 - loss: 0.4677\n",
      "Epoch 13/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7876 - loss: 0.4679\n",
      "Epoch 14/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7754 - loss: 0.4735\n",
      "Epoch 15/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7722 - loss: 0.4720\n",
      "Epoch 16/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7803 - loss: 0.4815\n",
      "Epoch 17/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7748 - loss: 0.4748\n",
      "Epoch 18/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7746 - loss: 0.4612\n",
      "Epoch 19/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7859 - loss: 0.4644\n",
      "Epoch 20/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7646 - loss: 0.4648\n",
      "Epoch 21/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7834 - loss: 0.4627\n",
      "Epoch 22/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7887 - loss: 0.4632\n",
      "Epoch 23/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7836 - loss: 0.4620\n",
      "Epoch 24/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7779 - loss: 0.4679\n",
      "Epoch 25/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8020 - loss: 0.4362\n",
      "Epoch 26/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7862 - loss: 0.4527\n",
      "Epoch 27/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7895 - loss: 0.4498\n",
      "Epoch 28/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7882 - loss: 0.4540\n",
      "Epoch 29/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8146 - loss: 0.4268\n",
      "Epoch 30/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8034 - loss: 0.4360\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7457 - loss: 0.5329\n",
      "Epoch 2/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7791 - loss: 0.4934\n",
      "Epoch 3/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7818 - loss: 0.4809\n",
      "Epoch 4/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7607 - loss: 0.5111\n",
      "Epoch 5/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7899 - loss: 0.4597\n",
      "Epoch 6/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7920 - loss: 0.4618\n",
      "Epoch 7/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7824 - loss: 0.4739\n",
      "Epoch 8/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7994 - loss: 0.4567\n",
      "Epoch 9/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8010 - loss: 0.4648\n",
      "Epoch 10/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7859 - loss: 0.4766\n",
      "Epoch 11/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7852 - loss: 0.4702\n",
      "Epoch 12/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8052 - loss: 0.4514\n",
      "Epoch 13/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8005 - loss: 0.4454\n",
      "Epoch 14/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7859 - loss: 0.4727\n",
      "Epoch 15/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7944 - loss: 0.4554\n",
      "Epoch 16/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7960 - loss: 0.4598\n",
      "Epoch 17/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7896 - loss: 0.4571\n",
      "Epoch 18/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8023 - loss: 0.4513\n",
      "Epoch 19/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8029 - loss: 0.4512\n",
      "Epoch 20/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8097 - loss: 0.4498\n",
      "Epoch 21/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7968 - loss: 0.4516\n",
      "Epoch 22/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8022 - loss: 0.4545\n",
      "Epoch 23/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7921 - loss: 0.4651\n",
      "Epoch 24/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8099 - loss: 0.4331\n",
      "Epoch 25/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8062 - loss: 0.4323\n",
      "Epoch 26/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7832 - loss: 0.4568\n",
      "Epoch 27/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8042 - loss: 0.4395\n",
      "Epoch 28/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7814 - loss: 0.4676\n",
      "Epoch 29/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8109 - loss: 0.4205\n",
      "Epoch 30/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7925 - loss: 0.4600\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7469 - loss: 0.5168\n",
      "Epoch 2/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7733 - loss: 0.4897\n",
      "Epoch 3/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7946 - loss: 0.4536\n",
      "Epoch 4/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7872 - loss: 0.4572\n",
      "Epoch 5/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7891 - loss: 0.4610\n",
      "Epoch 6/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7785 - loss: 0.4728\n",
      "Epoch 7/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8060 - loss: 0.4444\n",
      "Epoch 8/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7887 - loss: 0.4516\n",
      "Epoch 9/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8066 - loss: 0.4421\n",
      "Epoch 10/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7997 - loss: 0.4525\n",
      "Epoch 11/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7993 - loss: 0.4423\n",
      "Epoch 12/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7912 - loss: 0.4497\n",
      "Epoch 13/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8071 - loss: 0.4379\n",
      "Epoch 14/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7956 - loss: 0.4605\n",
      "Epoch 15/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7988 - loss: 0.4448\n",
      "Epoch 16/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8027 - loss: 0.4527\n",
      "Epoch 17/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7998 - loss: 0.4424\n",
      "Epoch 18/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7998 - loss: 0.4381\n",
      "Epoch 19/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7778 - loss: 0.4540\n",
      "Epoch 20/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7979 - loss: 0.4562\n",
      "Epoch 21/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7884 - loss: 0.4536\n",
      "Epoch 22/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7988 - loss: 0.4466\n",
      "Epoch 23/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8093 - loss: 0.4425\n",
      "Epoch 24/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8086 - loss: 0.4289\n",
      "Epoch 25/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8074 - loss: 0.4380\n",
      "Epoch 26/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8106 - loss: 0.4316\n",
      "Epoch 27/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8115 - loss: 0.4311\n",
      "Epoch 28/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8090 - loss: 0.4312\n",
      "Epoch 29/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8123 - loss: 0.4268\n",
      "Epoch 30/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8201 - loss: 0.4221\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7186 - loss: 0.5416\n",
      "Epoch 2/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7757 - loss: 0.4929\n",
      "Epoch 3/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7853 - loss: 0.4843\n",
      "Epoch 4/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7569 - loss: 0.5001\n",
      "Epoch 5/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7707 - loss: 0.4769\n",
      "Epoch 6/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7748 - loss: 0.4790\n",
      "Epoch 7/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7580 - loss: 0.5051\n",
      "Epoch 8/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7728 - loss: 0.4945\n",
      "Epoch 9/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7763 - loss: 0.4773\n",
      "Epoch 10/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7841 - loss: 0.4744\n",
      "Epoch 11/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7585 - loss: 0.4860\n",
      "Epoch 12/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7648 - loss: 0.4833\n",
      "Epoch 13/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7555 - loss: 0.4865\n",
      "Epoch 14/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7791 - loss: 0.4740\n",
      "Epoch 15/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7804 - loss: 0.4730\n",
      "Epoch 16/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7707 - loss: 0.4712\n",
      "Epoch 17/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7747 - loss: 0.4688\n",
      "Epoch 18/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7824 - loss: 0.4766\n",
      "Epoch 19/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7788 - loss: 0.4674\n",
      "Epoch 20/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7856 - loss: 0.4655\n",
      "Epoch 21/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7770 - loss: 0.4604\n",
      "Epoch 22/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8033 - loss: 0.4356\n",
      "Epoch 23/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7936 - loss: 0.4384\n",
      "Epoch 24/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7745 - loss: 0.4653\n",
      "Epoch 25/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7994 - loss: 0.4414\n",
      "Epoch 26/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7793 - loss: 0.4548\n",
      "Epoch 27/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7910 - loss: 0.4527\n",
      "Epoch 28/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7987 - loss: 0.4371\n",
      "Epoch 29/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7885 - loss: 0.4542\n",
      "Epoch 30/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7935 - loss: 0.4328\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/test/anaconda3/envs/saurav_sir_ann/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7451 - loss: 0.5233\n",
      "Epoch 2/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7782 - loss: 0.4933\n",
      "Epoch 3/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7891 - loss: 0.4713\n",
      "Epoch 4/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7692 - loss: 0.4941\n",
      "Epoch 5/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7998 - loss: 0.4702\n",
      "Epoch 6/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7847 - loss: 0.4693\n",
      "Epoch 7/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8032 - loss: 0.4558\n",
      "Epoch 8/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7799 - loss: 0.4761\n",
      "Epoch 9/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7902 - loss: 0.4790\n",
      "Epoch 10/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7948 - loss: 0.4709\n",
      "Epoch 11/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7954 - loss: 0.4559\n",
      "Epoch 12/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7923 - loss: 0.4724\n",
      "Epoch 13/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7953 - loss: 0.4594\n",
      "Epoch 14/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7977 - loss: 0.4538\n",
      "Epoch 15/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8019 - loss: 0.4451\n",
      "Epoch 16/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7945 - loss: 0.4605\n",
      "Epoch 17/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8021 - loss: 0.4520\n",
      "Epoch 18/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7817 - loss: 0.4733\n",
      "Epoch 19/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7979 - loss: 0.4572\n",
      "Epoch 20/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8018 - loss: 0.4393\n",
      "Epoch 21/30\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7867 - loss: 0.4635\n",
      "Epoch 22/30\n",
      "\u001b[1m 37/156\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8008 - loss: 0.4637"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assuming X_train, y_train, X_val, y_val have been created\n",
    "\n",
    "# Define the LSTM model\n",
    "def create_model(units=50, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(units=units))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'model__units': [20, 50, 80],\n",
    "    'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [20, 30, 40]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)  # 3-fold cross-validation\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Grid Search\n",
    "\n",
    "# # import os\n",
    "# # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# # Assuming X_train, y_train, X_val, y_val have been created\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def create_model(units_layer1=50,units_layer2=50, learning_rate=0.001):\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(units=units_layer1, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "#     model.add(LSTM(units=units_layer2))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Create a KerasClassifier\n",
    "# model = KerasClassifier(build_fn=create_model, metrics=['accuracy'],verbose=0)\n",
    "\n",
    "# # Define the hyperparameter grid\n",
    "# # param_grid = {\n",
    "# #     'model__units': [20, 50, 80],\n",
    "# #     'model__learning_rate': [0.01, 0.001, 0.0001],\n",
    "# #     'batch_size': [16, 32, 64],\n",
    "# #     'epochs': [20, 30, 40]\n",
    "# # }\n",
    "\n",
    "# param_grid = {\n",
    "#     'model__units': [20,50,80],\n",
    "#     'model__learning_rate': [0.001, 0.0001],\n",
    "#     'batch_size': [32, 64],\n",
    "#     'epochs': [20, 50]\n",
    "# }\n",
    "# param_grid = {\n",
    "#     'model__units_layer1': [50,100],\n",
    "#     'model__units_layer2': [25,50],\n",
    "#     'model__learning_rate': [0.001, 0.0001],\n",
    "#     'batch_size': [32],\n",
    "#     'epochs': [50]\n",
    "# }\n",
    "\n",
    "# model = KerasClassifier(model=create_model, optimizer='adam', verbose=0)\n",
    "\n",
    "# # Fit and predict\n",
    "# # model.fit(X_train, y_train)\n",
    "# # predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "# # # Create a GridSearchCV object\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, error_score='raise')  # 3-fold cross-validation\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best hyperparameters\n",
    "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saurav_sir_ann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
